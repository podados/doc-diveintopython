Chapter 10. Scripts and Streams
================================
10.1. Abstracting input sources
--------------------------------



One of Python's greatest strengths is its dynamic binding, and one powerful use
of dynamic binding is the file-like object.

Many functions which require an input source could simply take a filename, go
open the file for reading, read it, and close it when they're done. But they
don't. Instead, they take a file-like object.

In the simplest case, a file-like object is any object with a read method with
an optional size parameter, which returns a string. When called with no size
parameter, it reads everything there is to read from the input source and
returns all the data as a single string. When called with a size parameter, it
reads that much from the input source and returns that much data; when called
again, it picks up where it left off and returns the next chunk of data.

This is how reading from real files works; the difference is that you're not
limiting yourself to real files. The input source could be anything: a file on
disk, a web page, even a hard-coded string. As long as you pass a file-like
object to the function, and the function simply calls the object's read method,
the function can handle any kind of input source without specific code to
handle each kind.

In case you were wondering how this relates to XML processing, minidom.parse is
one such function which can take a file-like object.


Example 10.1. Parsing XML from a file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> from xml.dom import minidom
    >>> fsock = open('binary.xml')    (1)
    >>> xmldoc = minidom.parse(fsock) (2)
    >>> fsock.close()                 (3)
    >>> print xmldoc.toxml()          (4)
    <?xml version="1.0" ?>
    <grammar>
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    <ref id="byte">
      <p><xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/>\
    <xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/></p>
    </ref>
    </grammar>

(1) First, you open the file on disk. This gives you a file object.
(2) You pass the file object to minidom.parse, which calls the read method of
    fsock and reads the XML document from the file on disk.
(3) Be sure to call the close method of the file object after you're done with
    it. minidom.parse will not do this for you.
(4) Calling the toxml() method on the returned XML document prints out the
    entire thing.


Well, that all seems like a colossal waste of time. After all, you've already
seen that minidom.parse can simply take the filename and do all the opening and
closing nonsense automatically. And it's true that if you know you're just
going to be parsing a local file, you can pass the filename and minidom.parse
is smart enough to Do The Right Thing(tm). But notice how similar -- and easy
-- it is to parse an XML document straight from the Internet.


Example 10.2. Parsing XML from a URL
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> import urllib
    >>> usock = urllib.urlopen('http://slashdot.org/slashdot.rdf') (1)
    >>> xmldoc = minidom.parse(usock)                              (2)
    >>> usock.close()                                              (3)
    >>> print xmldoc.toxml()                                       (4)
    <?xml version="1.0" ?>
    <rdf:RDF xmlns="http://my.netscape.com/rdf/simple/0.9/"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">

<channel>
<title>Slashdot</title>
<link>http://slashdot.org/</link>
<description>News for nerds, stuff that matters</description>
</channel>

<image>
<title>Slashdot</title>
<url>http://images.slashdot.org/topics/topicslashdot.gif</url>
<link>http://slashdot.org/</link>
</image>

<item>
<title>To HDTV or Not to HDTV?</title>
<link>http://slashdot.org/article.pl?sid=01/12/28/0421241</link>
</item>

[...snip...]

(1) As you saw in a previous chapter, urlopen takes a web page URL and returns
    a file-like object. Most importantly, this object has a read method which
    returns the HTML source of the web page.
(2) Now you pass the file-like object to minidom.parse, which obediently calls
    the read method of the object and parses the XML data that the read method
    returns. The fact that this XML data is now coming straight from a web page
    is completely irrelevant. minidom.parse doesn't know about web pages, and
    it doesn't care about web pages; it just knows about file-like objects.
(3) As soon as you're done with it, be sure to close the file-like object that
    urlopen gives you.
(4) By the way, this URL is real, and it really is XML. It's an XML
    representation of the current headlines on Slashdot (http://slashdot.org/),
    a technical news and gossip site.



Example 10.3. Parsing XML from a string (the easy but inflexible way)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> contents = "<grammar><ref id='bit'><p>0</p><p>1</p></ref></grammar>"
    >>> xmldoc = minidom.parseString(contents) (1)
    >>> print xmldoc.toxml()
    <?xml version="1.0" ?>
    <grammar><ref id="bit"><p>0</p><p>1</p></ref></grammar>

(1) minidom has a method, parseString, which takes an entire XML document as a
    string and parses it. You can use this instead of minidom.parse if you know
    you already have your entire XML document in a string.


OK, so you can use the minidom.parse function for parsing both local files and
remote URLs, but for parsing strings, you use... a different function. That
means that if you want to be able to take input from a file, a URL, or a
string, you'll need special logic to check whether it's a string, and call the
parseString function instead. How unsatisfying.

If there were a way to turn a string into a file-like object, then you could
simply pass this object to minidom.parse. And in fact, there is a module
specifically designed for doing just that: StringIO.


Example 10.4. Introducing StringIO
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> contents = "<grammar><ref id='bit'><p>0</p><p>1</p></ref></grammar>"
    >>> import StringIO
    >>> ssock = StringIO.StringIO(contents)   (1)
    >>> ssock.read()                          (2)
    "<grammar><ref id='bit'><p>0</p><p>1</p></ref></grammar>"
    >>> ssock.read()                          (3)
    ''
    >>> ssock.seek(0)                         (4)
    >>> ssock.read(15)                        (5)
    '<grammar><ref i'
    >>> ssock.read(15)
    "d='bit'><p>0</p"
    >>> ssock.read()
    '><p>1</p></ref></grammar>'
    >>> ssock.close()                         (6)

(1) The StringIO module contains a single class, also called StringIO, which
    allows you to turn a string into a file-like object. The StringIO class
    takes the string as a parameter when creating an instance.
(2) Now you have a file-like object, and you can do all sorts of file-like
    things with it. Like read, which returns the original string.
(3) Calling read again returns an empty string. This is how real file objects
    work too; once you read the entire file, you can't read any more without
    explicitly seeking to the beginning of the file. The StringIO object works
    the same way.
(4) You can explicitly seek to the beginning of the string, just like seeking
    through a file, by using the seek method of the StringIO object.
(5) You can also read the string in chunks, by passing a size parameter to the
    read method.
(6) At any time, read will return the rest of the string that you haven't read
    yet. All of this is exactly how file objects work; hence the term file-like
    object.



Example 10.5. Parsing XML from a string (the file-like object way)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> contents = "<grammar><ref id='bit'><p>0</p><p>1</p></ref></grammar>"
    >>> ssock = StringIO.StringIO(contents)
    >>> xmldoc = minidom.parse(ssock) (1)
    >>> ssock.close()
    >>> print xmldoc.toxml()
    <?xml version="1.0" ?>
    <grammar><ref id="bit"><p>0</p><p>1</p></ref></grammar>

(1) Now you can pass the file-like object (really a StringIO) to minidom.parse,
    which will call the object's read method and happily parse away, never
    knowing that its input came from a hard-coded string.


So now you know how to use a single function, minidom.parse, to parse an XML
document stored on a web page, in a local file, or in a hard-coded string. For
a web page, you use urlopen to get a file-like object; for a local file, you
use open; and for a string, you use StringIO. Now let's take it one step
further and generalize these differences as well.


Example 10.6. openAnything
~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    def openAnything(source):                  (1)
        # try to open with urllib (if source is http, ftp, or file URL)
        import urllib                         
        try:                                  
            return urllib.urlopen(source)      (2)
        except (IOError, OSError):            
            pass                              
    
        # try to open with native open function (if source is pathname)
        try:                                  
            return open(source)                (3)
        except (IOError, OSError):            
            pass                              
    
        # treat source as string
        import StringIO                       
        return StringIO.StringIO(str(source))  (4)



(1) The openAnything function takes a single parameter, source, and returns a
    file-like object. source is a string of some sort; it can either be a URL
    (like 'http://slashdot.org/slashdot.rdf'), a full or partial pathname to a
    local file (like 'binary.xml'), or a string that contains actual XML data
    to be parsed.
(2) First, you see if source is a URL. You do this through brute force: you try
    to open it as a URL and silently ignore errors caused by trying to open
    something which is not a URL. This is actually elegant in the sense that,
    if urllib ever supports new types of URLs in the future, you will also
    support them without recoding. If urllib is able to open source, then the
    return kicks you out of the function immediately and the following try
    statements never execute.
(3) On the other hand, if urllib yelled at you and told you that source wasn't
    a valid URL, you assume it's a path to a file on disk and try to open it.
    Again, you don't do anything fancy to check whether source is a valid
    filename or not (the rules for valid filenames vary wildly between
    different platforms anyway, so you'd probably get them wrong anyway).
    Instead, you just blindly open the file, and silently trap any errors.
(4) By this point, you need to assume that source is a string that has
    hard-coded data in it (since nothing else worked), so you use StringIO to
    create a file-like object out of it and return that. (In fact, since you're
    using the str function, source doesn't even need to be a string; it could
    be any object, and you'll use its string representation, as defined by its
    __str__ special method.)


Now you can use this openAnything function in conjunction with minidom.parse to
make a function that takes a source that refers to an XML document somehow
(either as a URL, or a local filename, or a hard-coded XML document in a
string) and parses it.


Example 10.7. Using openAnything in kgp.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    class KantGenerator:
        def _load(self, source):
            sock = toolbox.openAnything(source)
            xmldoc = minidom.parse(sock).documentElement
            sock.close()
            return xmldoc



10.2. Standard input, output, and error
----------------------------------------



UNIX users are already familiar with the concept of standard input, standard
output, and standard error. This section is for the rest of you.

Standard output and standard error (commonly abbreviated stdout and stderr) are
pipes that are built into every UNIX system. When you print something, it goes
to the stdout pipe; when your program crashes and prints out debugging
information (like a traceback in Python), it goes to the stderr pipe. Both of
these pipes are ordinarily just connected to the terminal window where you are
working, so when a program prints, you see the output, and when a program
crashes, you see the debugging information. (If you're working on a system with
a window-based Python IDE, stdout and stderr default to your "Interactive
Window".)


Example 10.8. Introducing stdout and stderr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> for i in range(3):
    ...     print 'Dive in'             (1)
    Dive in
    Dive in
    Dive in
    >>> import sys
    >>> for i in range(3):
    ...     sys.stdout.write('Dive in') (2)
    Dive inDive inDive in
    >>> for i in range(3):
    ...     sys.stderr.write('Dive in') (3)
    Dive inDive inDive in

(1) As you saw in Example 6.9, ??Simple Counters??, you can use Python's
    built-in range function to build simple counter loops that repeat something
    a set number of times.
(2) stdout is a file-like object; calling its write function will print out
    whatever string you give it. In fact, this is what the print function
    really does; it adds a carriage return to the end of the string you're
    printing, and calls sys.stdout.write.
(3) In the simplest case, stdout and stderr send their output to the same
    place: the Python IDE (if you're in one), or the terminal (if you're
    running Python from the command line). Like stdout, stderr does not add
    carriage returns for you; if you want them, add them yourself.


stdout and stderr are both file-like objects, like the ones you discussed in
Section 10.1, ??Abstracting input sources??, but they are both write-only. They
have no read method, only write. Still, they are file-like objects, and you can
assign any other file- or file-like object to them to redirect their output.


Example 10.9. Redirecting output
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    [you@localhost kgp]$ python stdout.py
    Dive in
    [you@localhost kgp]$ cat out.log
    This message will be logged instead of displayed



(On Windows, you can use type instead of cat to display the contents of a
file.)

If you have not already done so, you can download this and other examples (
http://diveintopython.org/download/diveintopython-examples-5.4.zip) used in
this book.


::

    #stdout.py
    import sys
    
    print 'Dive in'                                          (1)
    saveout = sys.stdout                                     (2)
    fsock = open('out.log', 'w')                             (3)
    sys.stdout = fsock                                       (4)
    print 'This message will be logged instead of displayed' (5)
    sys.stdout = saveout                                     (6)
    fsock.close()                                            (7)



(1) This will print to the IDE "Interactive Window" (or the terminal, if
    running the script from the command line).
(2) Always save stdout before redirecting it, so you can set it back to normal
    later.
(3) Open a file for writing. If the file doesn't exist, it will be created. If
    the file does exist, it will be overwritten.
(4) Redirect all further output to the new file you just opened.
(5) This will be "printed" to the log file only; it will not be visible in the
    IDE window or on the screen.
(6) Set stdout back to the way it was before you mucked with it.
(7) Close the log file.


Redirecting stderr works exactly the same way, using sys.stderr instead of
sys.stdout.


Example 10.10. Redirecting error information
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    [you@localhost kgp]$ python stderr.py
    [you@localhost kgp]$ cat error.log
    Traceback (most recent line last):
      File "stderr.py", line 5, in ?
        raise Exception, 'this error will be logged'
    Exception: this error will be logged



If you have not already done so, you can download this and other examples (
http://diveintopython.org/download/diveintopython-examples-5.4.zip) used in
this book.


::

    #stderr.py
    import sys
    
    fsock = open('error.log', 'w')               (1)
    sys.stderr = fsock                           (2)
    raise Exception, 'this error will be logged' (3) (4)



(1) Open the log file where you want to store debugging information.
(2) Redirect standard error by assigning the file object of the newly-opened
    log file to stderr.
(3) Raise an exception. Note from the screen output that this does not print
    anything on screen. All the normal traceback information has been written
    to error.log.
(4) Also note that you're not explicitly closing your log file, nor are you
    setting stderr back to its original value. This is fine, since once the
    program crashes (because of the exception), Python will clean up and close
    the file for us, and it doesn't make any difference that stderr is never
    restored, since, as I mentioned, the program crashes and Python ends.
    Restoring the original is more important for stdout, if you expect to go do
    other stuff within the same script afterwards.


Since it is so common to write error messages to standard error, there is a
shorthand syntax that can be used instead of going through the hassle of
redirecting it outright.


Example 10.11. Printing to stderr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> print 'entering function'
    entering function
    >>> import sys
    >>> print >> sys.stderr, 'entering function' (1)
    entering function

(1) This shorthand syntax of the print statement can be used to write to any
    open file, or file-like object. In this case, you can redirect a single
    print statement to stderr without affecting subsequent print statements.


Standard input, on the other hand, is a read-only file object, and it
represents the data flowing into the program from some previous program. This
will likely not make much sense to classic Mac OS users, or even Windows users
unless you were ever fluent on the MS-DOS command line. The way it works is
that you can construct a chain of commands in a single line, so that one
program's output becomes the input for the next program in the chain. The first
program simply outputs to standard output (without doing any special
redirecting itself, just doing normal print statements or whatever), and the
next program reads from standard input, and the operating system takes care of
connecting one program's output to the next program's input.


Example 10.12. Chaining commands
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    [you@localhost kgp]$ python kgp.py -g binary.xml         (1)
    01100111
    [you@localhost kgp]$ cat binary.xml                      (2)
    <?xml version="1.0"?>
    <!DOCTYPE grammar PUBLIC "-//diveintopython.org//DTD Kant Generator Pro v1.0//EN" "kgp.dtd">
    <grammar>
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    <ref id="byte">
      <p><xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/>\
    <xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/></p>
    </ref>
    </grammar>
    [you@localhost kgp]$ cat binary.xml | python kgp.py -g - (3) (4)
    10110001



(1) As you saw in Section 9.1, ??Diving in??, this will print a string of eight
    random bits, 0 or 1.
(2) This simply prints out the entire contents of binary.xml. (Windows users
    should use type instead of cat.)
(3) This prints the contents of binary.xml, but the "|" character, called the "
    pipe" character, means that the contents will not be printed to the screen.
    Instead, they will become the standard input of the next command, which in
    this case calls your Python script.
(4) Instead of specifying a module (like binary.xml), you specify "-", which
    causes your script to load the grammar from standard input instead of from
    a specific file on disk. (More on how this happens in the next example.) So
    the effect is the same as the first syntax, where you specified the grammar
    filename directly, but think of the expansion possibilities here. Instead
    of simply doing cat binary.xml, you could run a script that dynamically
    generates the grammar, then you can pipe it into your script. It could come
    from anywhere: a database, or some grammar-generating meta-script, or
    whatever. The point is that you don't need to change your kgp.py script at
    all to incorporate any of this functionality. All you need to do is be able
    to take grammar files from standard input, and you can separate all the
    other logic into another program.


So how does the script "know" to read from standard input when the grammar file
is "-"? It's not magic; it's just code.


Example 10.13. Reading from standard input in kgp.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    def openAnything(source):
        if source == "-":    (1)
            import sys
            return sys.stdin
    
        # try to open with urllib (if source is http, ftp, or file URL)
        import urllib
        try:
    
    [... snip ...]



(1) This is the openAnything function from toolbox.py, which you previously
    examined in Section 10.1, ??Abstracting input sources??. All you've done is
    add three lines of code at the beginning of the function to check if the
    source is "-"; if so, you return sys.stdin. Really, that's it! Remember,
    stdin is a file-like object with a read method, so the rest of the code (in
    kgp.py, where you call openAnything) doesn't change a bit.

10.3. Caching node lookups
---------------------------



kgp.py employs several tricks which may or may not be useful to you in your XML
processing. The first one takes advantage of the consistent structure of the
input documents to build a cache of nodes.

A grammar file defines a series of ref elements. Each ref contains one or more
p elements, which can contain a lot of different things, including xrefs.
Whenever you encounter an xref, you look for a corresponding ref element with
the same id attribute, and choose one of the ref element's children and parse
it. (You'll see how this random choice is made in the next section.)

This is how you build up the grammar: define ref elements for the smallest
pieces, then define ref elements which "include" the first ref elements by
using xref, and so forth. Then you parse the "largest" reference and follow
each xref, and eventually output real text. The text you output depends on the
(random) decisions you make each time you fill in an xref, so the output is
different each time.

This is all very flexible, but there is one downside: performance. When you
find an xref and need to find the corresponding ref element, you have a
problem. The xref has an id attribute, and you want to find the ref element
that has that same id attribute, but there is no easy way to do that. The slow
way to do it would be to get the entire list of ref elements each time, then
manually loop through and look at each id attribute. The fast way is to do that
once and build a cache, in the form of a dictionary.


Example 10.14. loadGrammar
~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    def loadGrammar(self, grammar):                         
        self.grammar = self._load(grammar)                  
        self.refs = {}                                       (1)
        for ref in self.grammar.getElementsByTagName("ref"): (2)
            self.refs[ref.attributes["id"].value] = ref      (3) (4)

(1) Start by creating an empty dictionary, self.refs.
(2) As you saw in Section 9.5, ??Searching for elements??, getElementsByTagName
    returns a list of all the elements of a particular name. You easily can get
    a list of all the ref elements, then simply loop through that list.
(3) As you saw in Section 9.6, ??Accessing element attributes??, you can access
    individual attributes of an element by name, using standard dictionary
    syntax. So the keys of the self.refs dictionary will be the values of the
    id attribute of each ref element.
(4) The values of the self.refs dictionary will be the ref elements themselves.
    As you saw in Section 9.3, ??Parsing XML??, each element, each node, each
    comment, each piece of text in a parsed XML document is an object.


Once you build this cache, whenever you come across an xref and need to find
the ref element with the same id attribute, you can simply look it up in
self.refs.


Example 10.15. Using the ref element cache
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

        def do_xref(self, node):
            id = node.attributes["id"].value
            self.parse(self.randomChildElement(self.refs[id]))



You'll explore the randomChildElement function in the next section.

10.4. Finding direct children of a node
----------------------------------------



Another useful techique when parsing XML documents is finding all the direct
child elements of a particular element. For instance, in the grammar files, a
ref element can have several p elements, each of which can contain many things,
including other p elements. You want to find just the p elements that are
children of the ref, not p elements that are children of other p elements.

You might think you could simply use getElementsByTagName for this, but you
can't. getElementsByTagName searches recursively and returns a single list for
all the elements it finds. Since p elements can contain other p elements, you
can't use getElementsByTagName, because it would return nested p elements that
you don't want. To find only direct child elements, you'll need to do it
yourself.


Example 10.16. Finding direct child elements
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

        def randomChildElement(self, node):
            choices = [e for e in node.childNodes
                       if e.nodeType == e.ELEMENT_NODE] (1) (2) (3)
            chosen = random.choice(choices)             (4)
            return chosen                              



(1) As you saw in Example 9.9, ??Getting child nodes??, the childNodes
    attribute returns a list of all the child nodes of an element.
(2) However, as you saw in Example 9.11, ??Child nodes can be text??, the list
    returned by childNodes contains all different types of nodes, including
    text nodes. That's not what you're looking for here. You only want the
    children that are elements.
(3) Each node has a nodeType attribute, which can be ELEMENT_NODE, TEXT_NODE,
    COMMENT_NODE, or any number of other values. The complete list of possible
    values is in the __init__.py file in the xml.dom package. (See Section 9.2,
    ??Packages?? for more on packages.) But you're just interested in nodes
    that are elements, so you can filter the list to only include those nodes
    whose nodeType is ELEMENT_NODE.
(4) Once you have a list of actual elements, choosing a random one is easy.
    Python comes with a module called random which includes several useful
    functions. The random.choice function takes a list of any number of items
    and returns a random item. For example, if the ref elements contains
    several p elements, then choices would be a list of p elements, and chosen
    would end up being assigned exactly one of them, selected at random.

10.5. Creating separate handlers by node type
----------------------------------------------



The third useful XML processing tip involves separating your code into logical
functions, based on node types and element names. Parsed XML documents are made
up of various types of nodes, each represented by a Python object. The root
level of the document itself is represented by a Document object. The Document
then contains one or more Element objects (for actual XML tags), each of which
may contain other Element objects, Text objects (for bits of text), or Comment
objects (for embedded comments). Python makes it easy to write a dispatcher to
separate the logic for each node type.


Example 10.17. Class names of parsed XML objects
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> from xml.dom import minidom
    >>> xmldoc = minidom.parse('kant.xml') (1)
    >>> xmldoc
    <xml.dom.minidom.Document instance at 0x01359DE8>
    >>> xmldoc.__class__                   (2)
    <class xml.dom.minidom.Document at 0x01105D40>
    >>> xmldoc.__class__.__name__          (3)
    'Document'

(1) Assume for a moment that kant.xml is in the current directory.
(2) As you saw in Section 9.2, ??Packages??, the object returned by parsing an
    XML document is a Document object, as defined in the minidom.py in the
    xml.dom package. As you saw in Section 5.4, ??Instantiating Classes??,
    __class__ is built-in attribute of every Python object.
(3) Furthermore, __name__ is a built-in attribute of every Python class, and it
    is a string. This string is not mysterious; it's the same as the class name
    you type when you define a class yourself. (See Section 5.3, ??Defining
    Classes??.)


Fine, so now you can get the class name of any particular XML node (since each
XML node is represented as a Python object). How can you use this to your
advantage to separate the logic of parsing each node type? The answer is
getattr, which you first saw in Section 4.4, ??Getting Object References With
getattr??.


Example 10.18. parse, a generic XML node dispatcher
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    def parse(self, node):          
        parseMethod = getattr(self, "parse_%s" % node.__class__.__name__) (1) (2)
        parseMethod(node) (3)

(1) First off, notice that you're constructing a larger string based on the
    class name of the node you were passed (in the node argument). So if you're
    passed a Document node, you're constructing the string 'parse_Document',
    and so forth.
(2) Now you can treat that string as a function name, and get a reference to
    the function itself using getattr
(3) Finally, you can call that function and pass the node itself as an
    argument. The next example shows the definitions of each of these
    functions.



Example 10.19. Functions called by the parse dispatcher
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

        def parse_Document(self, node): (1)
            self.parse(node.documentElement)
    
        def parse_Text(self, node):    (2)
            text = node.data
            if self.capitalizeNextWord:
                self.pieces.append(text[0].upper())
                self.pieces.append(text[1:])
                self.capitalizeNextWord = 0
            else:
                self.pieces.append(text)
    
        def parse_Comment(self, node): (3)
            pass
    
        def parse_Element(self, node): (4)
            handlerMethod = getattr(self, "do_%s" % node.tagName)
            handlerMethod(node)



(1) parse_Document is only ever called once, since there is only one Document
    node in an XML document, and only one Document object in the parsed XML
    representation. It simply turns around and parses the root element of the
    grammar file.
(2) parse_Text is called on nodes that represent bits of text. The function
    itself does some special processing to handle automatic capitalization of
    the first word of a sentence, but otherwise simply appends the represented
    text to a list.
(3) parse_Comment is just a pass, since you don't care about embedded comments
    in the grammar files. Note, however, that you still need to define the
    function and explicitly make it do nothing. If the function did not exist,
    the generic parse function would fail as soon as it stumbled on a comment,
    because it would try to find the non-existent parse_Comment function.
    Defining a separate function for every node type, even ones you don't use,
    allows the generic parse function to stay simple and dumb.
(4) The parse_Element method is actually itself a dispatcher, based on the name
    of the element's tag. The basic idea is the same: take what distinguishes
    elements from each other (their tag names) and dispatch to a separate
    function for each of them. You construct a string like 'do_xref' (for an <
    xref> tag), find a function of that name, and call it. And so forth for
    each of the other tag names that might be found in the course of parsing a
    grammar file (<p> tags, <choice> tags).


In this example, the dispatch functions parse and parse_Element simply find
other methods in the same class. If your processing is very complex (or you
have many different tag names), you could break up your code into separate
modules, and use dynamic importing to import each module and call whatever
functions you needed. Dynamic importing will be discussed in Chapter 16,
Functional Programming.

10.6. Handling command-line arguments
--------------------------------------



Python fully supports creating programs that can be run on the command line,
complete with command-line arguments and either short- or long-style flags to
specify various options. None of this is XML-specific, but this script makes
good use of command-line processing, so it seemed like a good time to mention
it.

It's difficult to talk about command-line processing without understanding how
command-line arguments are exposed to your Python program, so let's write a
simple program to see them.


Example 10.20. Introducing sys.argv
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


If you have not already done so, you can download this and other examples (
http://diveintopython.org/download/diveintopython-examples-5.4.zip) used in
this book.


::

    #argecho.py
    import sys
    
    for arg in sys.argv: (1)
        print arg



(1) Each command-line argument passed to the program will be in sys.argv, which
    is just a list. Here you are printing each argument on a separate line.



Example 10.21. The contents of sys.argv
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    [you@localhost py]$ python argecho.py             (1)
    argecho.py
    [you@localhost py]$ python argecho.py abc def     (2)
    argecho.py
    abc
    def
    [you@localhost py]$ python argecho.py --help      (3)
    argecho.py
    --help
    [you@localhost py]$ python argecho.py -m kant.xml (4)
    argecho.py
    -m
    kant.xml



(1) The first thing to know about sys.argv is that it contains the name of the
    script you're calling. You will actually use this knowledge to your
    advantage later, in Chapter 16, Functional Programming. Don't worry about
    it for now.
(2) Command-line arguments are separated by spaces, and each shows up as a
    separate element in the sys.argv list.
(3) Command-line flags, like --help, also show up as their own element in the
    sys.argv list.
(4) To make things even more interesting, some command-line flags themselves
    take arguments. For instance, here you have a flag (-m) which takes an
    argument (kant.xml). Both the flag itself and the flag's argument are
    simply sequential elements in the sys.argv list. No attempt is made to
    associate one with the other; all you get is a list.


So as you can see, you certainly have all the information passed on the command
line, but then again, it doesn't look like it's going to be all that easy to
actually use it. For simple programs that only take a single argument and have
no flags, you can simply use sys.argv[1] to access the argument. There's no
shame in this; I do it all the time. For more complex programs, you need the
getopt module.


Example 10.22. Introducing getopt
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    def main(argv):                         
        grammar = "kant.xml"                 (1)
        try:                                
            opts, args = getopt.getopt(argv, "hg:d", ["help", "grammar="]) (2)
        except getopt.GetoptError:           (3)
            usage()                          (4)
            sys.exit(2)                     
    
    ...
    
    if __name__ == "__main__":
        main(sys.argv[1:])



(1) First off, look at the bottom of the example and notice that you're calling
    the main function with sys.argv[1:]. Remember, sys.argv[0] is the name of
    the script that you're running; you don't care about that for command-line
    processing, so you chop it off and pass the rest of the list.
(2) This is where all the interesting processing happens. The getopt function
    of the getopt module takes three parameters: the argument list (which you
    got from sys.argv[1:]), a string containing all the possible
    single-character command-line flags that this program accepts, and a list
    of longer command-line flags that are equivalent to the single-character
    versions. This is quite confusing at first glance, and is explained in more
    detail below.
(3) If anything goes wrong trying to parse these command-line flags, getopt
    will raise an exception, which you catch. You told getopt all the flags you
    understand, so this probably means that the end user passed some
    command-line flag that you don't understand.
(4) As is standard practice in the UNIX world, when the script is passed flags
    it doesn't understand, you print out a summary of proper usage and exit
    gracefully. Note that I haven't shown the usage function here. You would
    still need to code that somewhere and have it print out the appropriate
    summary; it's not automatic.


So what are all those parameters you pass to the getopt function? Well, the
first one is simply the raw list of command-line flags and arguments (not
including the first element, the script name, which you already chopped off
before calling the main function). The second is the list of short command-line
flags that the script accepts.



::

    "hg:d"
    
    -h
        print usage summary
    -g ...
        use specified grammar file or URL
    -d
        show debugging information while parsing




The first and third flags are simply standalone flags; you specify them or you
don't, and they do things (print help) or change state (turn on debugging).
However, the second flag (-g) must be followed by an argument, which is the
name of the grammar file to read from. In fact it can be a filename or a web
address, and you don't know which yet (you'll figure it out later), but you
know it has to be something. So you tell getopt this by putting a colon after
the g in that second parameter to the getopt function.

To further complicate things, the script accepts either short flags (like -h)
or long flags (like --help), and you want them to do the same thing. This is
what the third parameter to getopt is for, to specify a list of the long flags
that correspond to the short flags you specified in the second parameter.



::

    ["help", "grammar="]
    
    --help
        print usage summary
    --grammar ...
        use specified grammar file or URL




Three things of note here:
   
 1. All long flags are preceded by two dashes on the command line, but you don't
    include those dashes when calling getopt. They are understood.
 2. The --grammar flag must always be followed by an additional argument, just
    like the -g flag. This is notated by an equals sign, "grammar=".
 3. The list of long flags is shorter than the list of short flags, because the
    -d flag does not have a corresponding long version. This is fine; only -d
    will turn on debugging. But the order of short and long flags needs to be
    the same, so you'll need to specify all the short flags that do have
    corresponding long flags first, then all the rest of the short flags.


Confused yet? Let's look at the actual code and see if it makes sense in
context.


Example 10.23. Handling command-line arguments in kgp.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    def main(argv):                          (1)
        grammar = "kant.xml"                
        try:                                
            opts, args = getopt.getopt(argv, "hg:d", ["help", "grammar="])
        except getopt.GetoptError:          
            usage()                         
            sys.exit(2)                     
        for opt, arg in opts:                (2)
            if opt in ("-h", "--help"):      (3)
                usage()                     
                sys.exit()                  
            elif opt == '-d':                (4)
                global _debug               
                _debug = 1                  
            elif opt in ("-g", "--grammar"): (5)
                grammar = arg               
    
        source = "".join(args)               (6)
    
        k = KantGenerator(grammar, source)
        print k.output()



(1) The grammar variable will keep track of the grammar file you're using. You
    initialize it here in case it's not specified on the command line (using
    either the -g or the --grammar flag).
(2) The opts variable that you get back from getopt contains a list of tuples:
    flag and argument. If the flag doesn't take an argument, then arg will
    simply be None. This makes it easier to loop through the flags.
(3) getopt validates that the command-line flags are acceptable, but it doesn't
    do any sort of conversion between short and long flags. If you specify the
    -h flag, opt will contain "-h"; if you specify the --help flag, opt will
    contain "--help". So you need to check for both.
(4) Remember, the -d flag didn't have a corresponding long flag, so you only
    need to check for the short form. If you find it, you set a global variable
    that you'll refer to later to print out debugging information. (I used this
    during the development of the script. What, you thought all these examples
    worked on the first try?)
(5) If you find a grammar file, either with a -g flag or a --grammar flag, you
    save the argument that followed it (stored in arg) into the grammar
    variable, overwriting the default that you initialized at the top of the
    main function.
(6) That's it. You've looped through and dealt with all the command-line flags.
    That means that anything left must be command-line arguments. These come
    back from the getopt function in the args variable. In this case, you're
    treating them as source material for the parser. If there are no
    command-line arguments specified, args will be an empty list, and source
    will end up as the empty string.

10.7. Putting it all together
------------------------------



You've covered a lot of ground. Let's step back and see how all the pieces fit
together.

To start with, this is a script that takes its arguments on the command line,
using the getopt module.


::

    def main(argv):                         
    ...
        try:                                
            opts, args = getopt.getopt(argv, "hg:d", ["help", "grammar="])
        except getopt.GetoptError:          
    ...
        for opt, arg in opts:               
    ...



You create a new instance of the KantGenerator class, and pass it the grammar
file and source that may or may not have been specified on the command line.


::

        k = KantGenerator(grammar, source)
    
The KantGenerator instance automatically loads the grammar, which is an XML


file. You use your custom openAnything function to open the file (which could
be stored in a local file or a remote web server), then use the built-in
minidom parsing functions to parse the XML into a tree of Python objects.


::

    def _load(self, source):
        sock = toolbox.openAnything(source)
        xmldoc = minidom.parse(sock).documentElement
        sock.close()

Oh, and along the way, you take advantage of your knowledge of the structure of
the XML document to set up a little cache of references, which are just
elements in the XML document.


::

    def loadGrammar(self, grammar):                         
        for ref in self.grammar.getElementsByTagName("ref"):
            self.refs[ref.attributes["id"].value] = ref     

If you specified some source material on the command line, you use that;
otherwise you rip through the grammar looking for the "top-level" reference
(that isn't referenced by anything else) and use that as a starting point.


::

    def getDefaultSource(self):
        xrefs = {}
        for xref in self.grammar.getElementsByTagName("xref"):
            xrefs[xref.attributes["id"].value] = 1
        xrefs = xrefs.keys()
        standaloneXrefs = [e for e in self.refs.keys() if e not in xrefs]
        return '<xref id="%s"/>' % random.choice(standaloneXrefs)

Now you rip through the source material. The source material is also XML, and
you parse it one node at a time. To keep the code separated and more
maintainable, you use separate handlers for each node type.


::

    def parse_Element(self, node): 
        handlerMethod = getattr(self, "do_%s" % node.tagName)
        handlerMethod(node)

You bounce through the grammar, parsing all the children of each p element,


::

        def do_p(self, node):
    ...
            if doit:
                for child in node.childNodes: self.parse(child)



replacing choice elements with a random child,


::

    def do_choice(self, node):
        self.parse(self.randomChildElement(node))

and replacing xref elements with a random child of the corresponding ref
element, which you previously cached.


::

    def do_xref(self, node):
        id = node.attributes["id"].value
        self.parse(self.randomChildElement(self.refs[id]))

Eventually, you parse your way down to plain text,


::

        def parse_Text(self, node):    
            text = node.data
    ...
                self.pieces.append(text)



which you print out.


::

    def main(argv):                         
    ...
        k = KantGenerator(grammar, source)
        print k.output()



10.8. Summary
--------------



Python comes with powerful libraries for parsing and manipulating XML
documents. The minidom takes an XML file and parses it into Python objects,
providing for random access to arbitrary elements. Furthermore, this chapter
shows how Python can be used to create a "real" standalone command-line script,
complete with command-line flags, command-line arguments, error handling, even
the ability to take input from the piped result of a previous program.

Before moving on to the next chapter, you should be comfortable doing all of
these things:
   
  * Chaining programs with standard input and output
  * Defining dynamic dispatchers with getattr.
  * Using command-line flags and validating them with getopt

