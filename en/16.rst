Chapter 16. Functional Programming
===================================
16.1. Diving in
----------------



In Chapter 13, Unit Testing, you learned about the philosophy of unit testing.
In Chapter 14, Test-First Programming, you stepped through the implementation
of basic unit tests in Python. In Chapter 15, Refactoring, you saw how unit
testing makes large-scale refactoring easier. This chapter will build on those
sample programs, but here we will focus more on advanced Python-specific
techniques, rather than on unit testing itself.

The following is a complete Python program that acts as a cheap and simple
regression testing framework. It takes unit tests that you've written for
individual modules, collects them all into one big test suite, and runs them
all at once. I actually use this script as part of the build process for this
book; I have unit tests for several of the example programs (not just the
roman.py module featured in Chapter 13, Unit Testing), and the first thing my
automated build script does is run this program to make sure all my examples
still work. If this regression test fails, the build immediately stops. I don't
want to release non-working examples any more than you want to download them
and sit around scratching your head and yelling at your monitor and wondering
why they don't work.


Example 16.1. regression.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~


If you have not already done so, you can download this and other examples (
http://diveintopython.org/download/diveintopython-examples-5.4.zip) used in
this book.


::

    """Regression testing framework
    
    This module will search for scripts in the same directory named
    XYZtest.py.  Each such script should be a test suite that tests a
    module through PyUnit.  (As of Python 2.1, PyUnit is included in
    the standard library as "unittest".)  This script will aggregate all
    found test suites into one big test suite and run them all at once.
    """
    
    import sys, os, re, unittest
    
    def regressionTest():
        path = os.path.abspath(os.path.dirname(sys.argv[0]))   
        files = os.listdir(path)                               
        test = re.compile("test\.py$", re.IGNORECASE)          
        files = filter(test.search, files)                     
        filenameToModuleName = lambda f: os.path.splitext(f)[0]
        moduleNames = map(filenameToModuleName, files)         
        modules = map(__import__, moduleNames)                 
        load = unittest.defaultTestLoader.loadTestsFromModule  
        return unittest.TestSuite(map(load, modules))          
    
    if __name__ == "__main__":                   
        unittest.main(defaultTest="regressionTest")



Running this script in the same directory as the rest of the example scripts
that come with this book will find all the unit tests, named moduletest.py, run
them as a single test, and pass or fail them all at once.


Example 16.2. Sample output of regression.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    [you@localhost py]$ python regression.py -v
    help should fail with no object ... ok                             (1)
    help should return known result for apihelper ... ok
    help should honor collapse argument ... ok
    help should honor spacing argument ... ok
    buildConnectionString should fail with list input ... ok           (2)
    buildConnectionString should fail with string input ... ok
    buildConnectionString should fail with tuple input ... ok
    buildConnectionString handles empty dictionary ... ok
    buildConnectionString returns known result with known input ... ok
    fromRoman should only accept uppercase input ... ok                (3)
    toRoman should always return uppercase ... ok
    fromRoman should fail with blank string ... ok
    fromRoman should fail with malformed antecedents ... ok
    fromRoman should fail with repeated pairs of numerals ... ok
    fromRoman should fail with too many repeated numerals ... ok
    fromRoman should give known result with known input ... ok
    toRoman should give known result with known input ... ok
    fromRoman(toRoman(n))==n for all n ... ok
    toRoman should fail with non-integer input ... ok
    toRoman should fail with negative input ... ok
    toRoman should fail with large input ... ok
    toRoman should fail with 0 input ... ok
    kgp a ref test ... ok
    kgp b ref test ... ok
    kgp c ref test ... ok
    kgp d ref test ... ok
    kgp e ref test ... ok
    kgp f ref test ... ok
    kgp g ref test ... ok
    
    ----------------------------------------------------------------------
    Ran 29 tests in 2.799s
    
    OK



(1) The first 5 tests are from apihelpertest.py, which tests the example script
    from Chapter 4, The Power Of Introspection.
(2) The next 5 tests are from odbchelpertest.py, which tests the example script
    from Chapter 2, Your First Python Program.
(3) The rest are from romantest.py, which you studied in depth in Chapter 13,
    Unit Testing.

16.2. Finding the path
-----------------------



When running Python scripts from the command line, it is sometimes useful to
know where the currently running script is located on disk.

This is one of those obscure little tricks that is virtually impossible to
figure out on your own, but simple to remember once you see it. The key to it
is sys.argv. As you saw in Chapter 9, XML Processing, this is a list that holds
the list of command-line arguments. However, it also holds the name of the
running script, exactly as it was called from the command line, and this is
enough information to determine its location.


Example 16.3. fullpath.py
~~~~~~~~~~~~~~~~~~~~~~~~~~


If you have not already done so, you can download this and other examples (
http://diveintopython.org/download/diveintopython-examples-5.4.zip) used in
this book.


::

    import sys, os
    
    print 'sys.argv[0] =', sys.argv[0]             (1)
    pathname = os.path.dirname(sys.argv[0])        (2)
    print 'path =', pathname
    print 'full path =', os.path.abspath(pathname) (3)



(1) Regardless of how you run a script, sys.argv[0] will always contain the
    name of the script, exactly as it appears on the command line. This may or
    may not include any path information, as you'll see shortly.
(2) os.path.dirname takes a filename as a string and returns the directory path
    portion. If the given filename does not include any path information,
    os.path.dirname returns an empty string.
(3) os.path.abspath is the key here. It takes a pathname, which can be partial
    or even blank, and returns a fully qualified pathname.


os.path.abspath deserves further explanation. It is very flexible; it can take
any kind of pathname.


Example 16.4. Further explanation of os.path.abspath
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> import os
    >>> os.getcwd()                        (1)
    /home/you
    >>> os.path.abspath('')                (2)
    /home/you
    >>> os.path.abspath('.ssh')            (3)
    /home/you/.ssh
    >>> os.path.abspath('/home/you/.ssh') (4)
    /home/you/.ssh
    >>> os.path.abspath('.ssh/../foo/')    (5)
    /home/you/foo

(1) os.getcwd() returns the current working directory.
(2) Calling os.path.abspath with an empty string returns the current working
    directory, same as os.getcwd().
(3) Calling os.path.abspath with a partial pathname constructs a fully
    qualified pathname out of it, based on the current working directory.
(4) Calling os.path.abspath with a full pathname simply returns it.
(5) os.path.abspath also normalizes the pathname it returns. Note that this
    example worked even though I don't actually have a 'foo' directory.
    os.path.abspath never checks your actual disk; this is all just string
    manipulation.

    Note: os.path.abspath does not validate pathnames
    The pathnames and filenames you pass to os.path.abspath do not need to
    exist.

    Note: Normalizing pathnames
    os.path.abspath not only constructs full path names, it also normalizes
    them. That means that if you are in the /usr/ directory, os.path.abspath
    ('bin/../local/bin') will return /usr/local/bin. It normalizes the path by
    making it as simple as possible. If you just want to normalize a pathname
    like this without turning it into a full pathname, use os.path.normpath
    instead.



Example 16.5. Sample output from fullpath.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

[you@localhost py]$ python /home/you/diveintopython/common/py/fullpath.py (1)
sys.argv[0] = /home/you/diveintopython/common/py/fullpath.py
path = /home/you/diveintopython/common/py
full path = /home/you/diveintopython/common/py
[you@localhost diveintopython]$ python common/py/fullpath.py               (2)
sys.argv[0] = common/py/fullpath.py
path = common/py
full path = /home/you/diveintopython/common/py
[you@localhost diveintopython]$ cd common/py
[you@localhost py]$ python fullpath.py                                     (3)
sys.argv[0] = fullpath.py
path = 
full path = /home/you/diveintopython/common/py

(1) In the first case, sys.argv[0] includes the full path of the script. You
    can then use the os.path.dirname function to strip off the script name and
    return the full directory name, and os.path.abspath simply returns what you
    give it.
(2) If the script is run by using a partial pathname, sys.argv[0] will still
    contain exactly what appears on the command line. os.path.dirname will then
    give you a partial pathname (relative to the current directory), and
    os.path.abspath will construct a full pathname from the partial pathname.
(3) If the script is run from the current directory without giving any path,
    os.path.dirname will simply return an empty string. Given an empty string,
    os.path.abspath returns the current directory, which is what you want,
    since the script was run from the current directory.

    Note: os.path.abspath is cross-platform
    Like the other functions in the os and os.path modules, os.path.abspath is
    cross-platform. Your results will look slightly different than my examples
    if you're running on Windows (which uses backslash as a path separator) or
    Mac OS (which uses colons), but they'll still work. That's the whole point
    of the os module.


Addendum. One reader was dissatisfied with this solution, and wanted to be able
to run all the unit tests in the current directory, not the directory where
regression.py is located. He suggests this approach instead:


Example 16.6. Running scripts in the current directory
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

import sys, os, re, unittest

def regressionTest():
    path = os.getcwd()       (1)
    sys.path.append(path)    (2)
    files = os.listdir(path) (3)

(1) Instead of setting path to the directory where the currently running script
    is located, you set it to the current working directory instead. This will
    be whatever directory you were in before you ran the script, which is not
    necessarily the same as the directory the script is in. (Read that sentence
    a few times until you get it.)
(2) Append this directory to the Python library search path, so that when you
    dynamically import the unit test modules later, Python can find them. You
    didn't need to do this when path was the directory of the currently running
    script, because Python always looks in that directory.
(3) The rest of the function is the same.


This technique will allow you to re-use this regression.py script on multiple
projects. Just put the script in a common directory, then change to the
project's directory before running it. All of that project's unit tests will be
found and tested, instead of the unit tests in the common directory where
regression.py is located.

16.3. Filtering lists revisited
--------------------------------



You're already familiar with using list comprehensions to filter lists. There
is another way to accomplish this same thing, which some people feel is more
expressive.

Python has a built-in filter function which takes two arguments, a function and
a list, and returns a list.[7] The function passed as the first argument to
filter must itself take one argument, and the list that filter returns will
contain all the elements from the list passed to filter for which the function
passed to filter returns true.

Got all that? It's not as difficult as it sounds.


Example 16.7. Introducing filter
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> def odd(n):                 (1)
    ...     return n % 2
    ...     
    >>> li = [1, 2, 3, 5, 9, 10, 256, -3]
    >>> filter(odd, li)             (2)
    [1, 3, 5, 9, -3]
    >>> [e for e in li if odd(e)]   (3)
    >>> filteredList = []
    >>> for n in li:                (4)
    ...     if odd(n):
    ...         filteredList.append(n)
    ...     
    >>> filteredList
    [1, 3, 5, 9, -3]

(1) odd uses the built-in mod function "%" to return True if n is odd and False
    if n is even.
(2) filter takes two arguments, a function (odd) and a list (li). It loops
    through the list and calls odd with each element. If odd returns a true
    value (remember, any non-zero value is true in Python), then the element is
    included in the returned list, otherwise it is filtered out. The result is
    a list of only the odd numbers from the original list, in the same order as
    they appeared in the original.
(3) You could accomplish the same thing using list comprehensions, as you saw
    in Section 4.5, ??Filtering Lists??.
(4) You could also accomplish the same thing with a for loop. Depending on your
    programming background, this may seem more "straightforward", but functions
    like filter are much more expressive. Not only is it easier to write, it's
    easier to read, too. Reading the for loop is like standing too close to a
    painting; you see all the details, but it may take a few seconds to be able
    to step back and see the bigger picture: "Oh, you're just filtering the
    list!"



Example 16.8. filter in regression.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    files = os.listdir(path)                                (1)
    test = re.compile("test\.py$", re.IGNORECASE)           (2)
    files = filter(test.search, files)                      (3)

(1) As you saw in Section 16.2, ??Finding the path??, path may contain the full
    or partial pathname of the directory of the currently running script, or it
    may contain an empty string if the script is being run from the current
    directory. Either way, files will end up with the names of the files in the
    same directory as this script you're running.
(2) This is a compiled regular expression. As you saw in Section 15.3, ??
    Refactoring??, if you're going to use the same regular expression over and
    over, you should compile it for faster performance. The compiled object has
    a search method which takes a single argument, the string to search. If the
    regular expression matches the string, the search method returns a Match
    object containing information about the regular expression match; otherwise
    it returns None, the Python null value.
(3) For each element in the files list, you're going to call the search method
    of the compiled regular expression object, test. If the regular expression
    matches, the method will return a Match object, which Python considers to
    be true, so the element will be included in the list returned by filter. If
    the regular expression does not match, the search method will return None,
    which Python considers to be false, so the element will not be included.


Historical note. Versions of Python prior to 2.0 did not have list
comprehensions, so you couldn't filter using list comprehensions; the filter
function was the only game in town. Even with the introduction of list
comprehensions in 2.0, some people still prefer the old-style filter (and its
companion function, map, which you'll see later in this chapter). Both
techniques work at the moment, so which one you use is a matter of style. There
is discussion that map and filter might be deprecated in a future version of
Python, but no decision has been made.


Example 16.9. Filtering using list comprehensions instead
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    files = os.listdir(path)                               
    test = re.compile("test\.py$", re.IGNORECASE)          
    files = [f for f in files if test.search(f)] (1)

(1) This will accomplish exactly the same result as using the filter function.
    Which way is more expressive? That's up to you.

16.4. Mapping lists revisited
------------------------------



You're already familiar with using list comprehensions to map one list into
another. There is another way to accomplish the same thing, using the built-in
map function. It works much the same way as the filter function.


Example 16.10. Introducing map
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> def double(n):
    ...     return n*2
    ...     
    >>> li = [1, 2, 3, 5, 9, 10, 256, -3]
    >>> map(double, li)                       (1)
    [2, 4, 6, 10, 18, 20, 512, -6]
    >>> [double(n) for n in li]               (2)
    [2, 4, 6, 10, 18, 20, 512, -6]
    >>> newlist = []
    >>> for n in li:                          (3)
    ...     newlist.append(double(n))
    ...     
    >>> newlist
    [2, 4, 6, 10, 18, 20, 512, -6]

(1) map takes a function and a list[8] and returns a new list by calling the
    function with each element of the list in order. In this case, the function
    simply multiplies each element by 2.
(2) You could accomplish the same thing with a list comprehension. List
    comprehensions were first introduced in Python 2.0; map has been around
    forever.
(3) You could, if you insist on thinking like a Visual Basic programmer, use a
    for loop to accomplish the same thing.



Example 16.11. map with lists of mixed datatypes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> li = [5, 'a', (2, 'b')]
    >>> map(double, li)                       (1)
    [10, 'aa', (2, 'b', 2, 'b')]

(1) As a side note, I'd like to point out that map works just as well with
    lists of mixed datatypes, as long as the function you're using correctly
    handles each type. In this case, the double function simply multiplies the
    given argument by 2, and Python Does The Right Thing depending on the
    datatype of the argument. For integers, this means actually multiplying it
    by 2; for strings, it means concatenating the string with itself; for
    tuples, it means making a new tuple that has all of the elements of the
    original, then all of the elements of the original again.


All right, enough play time. Let's look at some real code.


Example 16.12. map in regression.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    filenameToModuleName = lambda f: os.path.splitext(f)[0] (1)
    moduleNames = map(filenameToModuleName, files)          (2)

(1) As you saw in Section 4.7, ??Using lambda Functions??, lambda defines an
    inline function. And as you saw in Example 6.17, ??Splitting Pathnames??,
    os.path.splitext takes a filename and returns a tuple (name, extension). So
    filenameToModuleName is a function which will take a filename and strip off
    the file extension, and return just the name.
(2) Calling map takes each filename listed in files, passes it to the function
    filenameToModuleName, and returns a list of the return values of each of
    those function calls. In other words, you strip the file extension off of
    each filename, and store the list of all those stripped filenames in
    moduleNames.


As you'll see in the rest of the chapter, you can extend this type of
data-centric thinking all the way to the final goal, which is to define and
execute a single test suite that contains the tests from all of those
individual test suites.

16.5. Data-centric programming
-------------------------------



By now you're probably scratching your head wondering why this is better than
using for loops and straight function calls. And that's a perfectly valid
question. Mostly, it's a matter of perspective. Using map and filter forces you
to center your thinking around your data.

In this case, you started with no data at all; the first thing you did was get
the directory path of the current script, and got a list of files in that
directory. That was the bootstrap, and it gave you real data to work with: a
list of filenames.

However, you knew you didn't care about all of those files, only the ones that
were actually test suites. You had too much data, so you needed to filter it.
How did you know which data to keep? You needed a test to decide, so you
defined one and passed it to the filter function. In this case you used a
regular expression to decide, but the concept would be the same regardless of
how you constructed the test.

Now you had the filenames of each of the test suites (and only the test suites,
since everything else had been filtered out), but you really wanted module
names instead. You had the right amount of data, but it was in the wrong format
. So you defined a function that would transform a single filename into a
module name, and you mapped that function onto the entire list. From one
filename, you can get a module name; from a list of filenames, you can get a
list of module names.

Instead of filter, you could have used a for loop with an if statement. Instead
of map, you could have used a for loop with a function call. But using for
loops like that is busywork. At best, it simply wastes time; at worst, it
introduces obscure bugs. For instance, you need to figure out how to test for
the condition "is this file a test suite?" anyway; that's the
application-specific logic, and no language can write that for us. But once
you've figured that out, do you really want go to all the trouble of defining a
new empty list and writing a for loop and an if statement and manually calling
append to add each element to the new list if it passes the condition and then
keeping track of which variable holds the new filtered data and which one holds
the old unfiltered data? Why not just define the test condition, then let
Python do the rest of that work for us?

Oh sure, you could try to be fancy and delete elements in place without
creating a new list. But you've been burned by that before. Trying to modify a
data structure that you're looping through can be tricky. You delete an
element, then loop to the next element, and suddenly you've skipped one. Is
Python one of the languages that works that way? How long would it take you to
figure it out? Would you remember for certain whether it was safe the next time
you tried? Programmers spend so much time and make so many mistakes dealing
with purely technical issues like this, and it's all pointless. It doesn't
advance your program at all; it's just busywork.

I resisted list comprehensions when I first learned Python, and I resisted
filter and map even longer. I insisted on making my life more difficult,
sticking to the familiar way of for loops and if statements and step-by-step
code-centric programming. And my Python programs looked a lot like Visual Basic
programs, detailing every step of every operation in every function. And they
had all the same types of little problems and obscure bugs. And it was all
pointless.

Let it all go. Busywork code is not important. Data is important. And data is
not difficult. It's only data. If you have too much, filter it. If it's not
what you want, map it. Focus on the data; leave the busywork behind.

16.6. Dynamically importing modules
------------------------------------



OK, enough philosophizing. Let's talk about dynamically importing modules.

First, let's look at how you normally import modules. The import module syntax
looks in the search path for the named module and imports it by name. You can
even import multiple modules at once this way, with a comma-separated list. You
did this on the very first line of this chapter's script.


Example 16.13. Importing multiple modules at once
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

import sys, os, re, unittest (1)

(1) This imports four modules at once: sys (for system functions and access to
    the command line parameters), os (for operating system functions like
    directory listings), re (for regular expressions), and unittest (for unit
    testing).


Now let's do the same thing, but with dynamic imports.


Example 16.14. Importing modules dynamically
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> sys = __import__('sys')           (1)
    >>> os = __import__('os')
    >>> re = __import__('re')
    >>> unittest = __import__('unittest')
    >>> sys                               (2)
    >>> <module 'sys' (built-in)>
    >>> os
    >>> <module 'os' from '/usr/local/lib/python2.2/os.pyc'>

(1) The built-in __import__ function accomplishes the same goal as using the
    import statement, but it's an actual function, and it takes a string as an
    argument.
(2) The variable sys is now the sys module, just as if you had said import sys.
    The variable os is now the os module, and so forth.


So __import__ imports a module, but takes a string argument to do it. In this
case the module you imported was just a hard-coded string, but it could just as
easily be a variable, or the result of a function call. And the variable that
you assign the module to doesn't need to match the module name, either. You
could import a series of modules and assign them to a list.


Example 16.15. Importing a list of modules dynamically
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> moduleNames = ['sys', 'os', 're', 'unittest'] (1)
    >>> moduleNames
    ['sys', 'os', 're', 'unittest']
    >>> modules = map(__import__, moduleNames)        (2)
    >>> modules                                       (3)
    [<module 'sys' (built-in)>,
    <module 'os' from 'c:\Python22\lib\os.pyc'>,
    <module 're' from 'c:\Python22\lib\re.pyc'>,
    <module 'unittest' from 'c:\Python22\lib\unittest.pyc'>]
    >>> modules[0].version                            (4)
    '2.2.2 (#37, Nov 26 2002, 10:24:37) [MSC 32 bit (Intel)]'
    >>> import sys
    >>> sys.version
    '2.2.2 (#37, Nov 26 2002, 10:24:37) [MSC 32 bit (Intel)]'

(1) moduleNames is just a list of strings. Nothing fancy, except that the
    strings happen to be names of modules that you could import, if you wanted
    to.
(2) Surprise, you wanted to import them, and you did, by mapping the __import__
    function onto the list. Remember, this takes each element of the list
    (moduleNames) and calls the function (__import__) over and over, once with
    each element of the list, builds a list of the return values, and returns
    the result.
(3) So now from a list of strings, you've created a list of actual modules.
    (Your paths may be different, depending on your operating system, where you
    installed Python, the phase of the moon, etc.)
(4) To drive home the point that these are real modules, let's look at some
    module attributes. Remember, modules[0] is the sys module, so modules
    [0].version is sys.version. All the other attributes and methods of these
    modules are also available. There's nothing magic about the import
    statement, and there's nothing magic about modules. Modules are objects.
    Everything is an object.


Now you should be able to put this all together and figure out what most of
this chapter's code sample is doing.

16.7. Putting it all together
------------------------------



You've learned enough now to deconstruct the first seven lines of this
chapter's code sample: reading a directory and importing selected modules
within it.


Example 16.16. The regressionTest function
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

def regressionTest():
    path = os.path.abspath(os.path.dirname(sys.argv[0]))   
    files = os.listdir(path)                               
    test = re.compile("test\.py$", re.IGNORECASE)          
    files = filter(test.search, files)                     
    filenameToModuleName = lambda f: os.path.splitext(f)[0]
    moduleNames = map(filenameToModuleName, files)         
    modules = map(__import__, moduleNames)                 
load = unittest.defaultTestLoader.loadTestsFromModule  
return unittest.TestSuite(map(load, modules))          

Let's look at it line by line, interactively. Assume that the current directory
is c:\diveintopython\py, which contains the examples that come with this book,
including this chapter's script. As you saw in Section 16.2, ??Finding the path
??, the script directory will end up in the path variable, so let's start
hard-code that and go from there.


Example 16.17. Step 1: Get all the files
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> import sys, os, re, unittest
    >>> path = r'c:\diveintopython\py'
    >>> files = os.listdir(path)                               
    >>> files (1)
    ['BaseHTMLProcessor.py', 'LICENSE.txt', 'apihelper.py', 'apihelpertest.py',
    'argecho.py', 'autosize.py', 'builddialectexamples.py', 'dialect.py',
    'fileinfo.py', 'fullpath.py', 'kgptest.py', 'makerealworddoc.py',
    'odbchelper.py', 'odbchelpertest.py', 'parsephone.py', 'piglatin.py',
    'plural.py', 'pluraltest.py', 'pyfontify.py', 'regression.py', 'roman.py', 'romantest.py',
    'uncurly.py', 'unicode2koi8r.py', 'urllister.py', 'kgp', 'plural', 'roman',
    'colorize.py']

(1) files is a list of all the files and directories in the script's directory.
    (If you've been running some of the examples already, you may also see some
    .pyc files in there as well.)



Example 16.18. Step 2: Filter to find the files you care about
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> test = re.compile("test\.py$", re.IGNORECASE)           (1)
    >>> files = filter(test.search, files)                      (2)
    >>> files                                                   (3)
    ['apihelpertest.py', 'kgptest.py', 'odbchelpertest.py', 'pluraltest.py', 'romantest.py']

(1) This regular expression will match any string that ends with test.py. Note
    that you need to escape the period, since a period in a regular expression
    usually means "match any single character", but you actually want to match
    a literal period instead.
(2) The compiled regular expression acts like a function, so you can use it to
    filter the large list of files and directories, to find the ones that match
    the regular expression.
(3) And you're left with the list of unit testing scripts, because they were
    the only ones named SOMETHINGtest.py.



Example 16.19. Step 3: Map filenames to module names
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> filenameToModuleName = lambda f: os.path.splitext(f)[0] (1)
    >>> filenameToModuleName('romantest.py')                    (2)
    'romantest'
    >>> filenameToModuleName('odchelpertest.py')
    'odbchelpertest'
    >>> moduleNames = map(filenameToModuleName, files)          (3)
    >>> moduleNames                                             (4)
    ['apihelpertest', 'kgptest', 'odbchelpertest', 'pluraltest', 'romantest']

(1) As you saw in Section 4.7, ??Using lambda Functions??, lambda is a
    quick-and-dirty way of creating an inline, one-line function. This one
    takes a filename with an extension and returns just the filename part,
    using the standard library function os.path.splitext that you saw in
    Example 6.17, ??Splitting Pathnames??.
(2) filenameToModuleName is a function. There's nothing magic about lambda
    functions as opposed to regular functions that you define with a def
    statement. You can call the filenameToModuleName function like any other,
    and it does just what you wanted it to do: strips the file extension off of
    its argument.
(3) Now you can apply this function to each file in the list of unit test
    files, using map.
(4) And the result is just what you wanted: a list of modules, as strings.



Example 16.20. Step 4: Mapping module names to modules
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> modules = map(__import__, moduleNames)                  (1)
    >>> modules                                                 (2)
    [<module 'apihelpertest' from 'apihelpertest.py'>,
    <module 'kgptest' from 'kgptest.py'>,
    <module 'odbchelpertest' from 'odbchelpertest.py'>,
    <module 'pluraltest' from 'pluraltest.py'>,
    <module 'romantest' from 'romantest.py'>]
    >>> modules[-1]                                             (3)
    <module 'romantest' from 'romantest.py'>

(1) As you saw in Section 16.6, ??Dynamically importing modules??, you can use
    a combination of map and __import__ to map a list of module names (as
    strings) into actual modules (which you can call or access like any other
    module).
(2) modules is now a list of modules, fully accessible like any other module.
(3) The last module in the list is the romantest module, just as if you had
    said import romantest.



Example 16.21. Step 5: Loading the modules into a test suite
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> load = unittest.defaultTestLoader.loadTestsFromModule  
    >>> map(load, modules)                     (1)
    [<unittest.TestSuite tests=[
      <unittest.TestSuite tests=[<apihelpertest.BadInput testMethod=testNoObject>]>,
      <unittest.TestSuite tests=[<apihelpertest.KnownValues testMethod=testApiHelper>]>,
      <unittest.TestSuite tests=[
        <apihelpertest.ParamChecks testMethod=testCollapse>, 
        <apihelpertest.ParamChecks testMethod=testSpacing>]>, 
        ...
      ]
    ]
    >>> unittest.TestSuite(map(load, modules)) (2)

(1) These are real module objects. Not only can you access them like any other
    module, instantiate classes and call functions, you can also introspect
    into the module to figure out which classes and functions it has in the
    first place. That's what the loadTestsFromModule method does: it
    introspects into each module and returns a unittest.TestSuite object for
    each module. Each TestSuite object actually contains a list of TestSuite
    objects, one for each TestCase class in your module, and each of those
    TestSuite objects contains a list of tests, one for each test method in
    your module.
(2) Finally, you wrap the list of TestSuite objects into one big test suite.
    The unittest module has no problem traversing this tree of nested test
    suites within test suites; eventually it gets down to an individual test
    method and executes it, verifies that it passes or fails, and moves on to
    the next one.


This introspection process is what the unittest module usually does for us.
Remember that magic-looking unittest.main() function that our individual test
modules called to kick the whole thing off? unittest.main() actually creates an
instance of unittest.TestProgram, which in turn creates an instance of a
unittest.defaultTestLoader and loads it up with the module that called it. (How
does it get a reference to the module that called it if you don't give it one?
By using the equally-magic __import__('__main__') command, which dynamically
imports the currently-running module. I could write a book on all the tricks
and techniques used in the unittest module, but then I'd never finish this
one.)


Example 16.22. Step 6: Telling unittest to use your test suite
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

if __name__ == "__main__":                   
    unittest.main(defaultTest="regressionTest") (1)

(1) Instead of letting the unittest module do all its magic for us, you've done
    most of it yourself. You've created a function (regressionTest) that
    imports the modules yourself, calls unittest.defaultTestLoader yourself,
    and wraps it all up in a test suite. Now all you need to do is tell
    unittest that, instead of looking for tests and building a test suite in
    the usual way, it should just call the regressionTest function, which
    returns a ready-to-use TestSuite.

16.8. Summary
--------------



The regression.py program and its output should now make perfect sense.

You should now feel comfortable doing all of these things:
   
  * Manipulating path information from the command line.
  * Filtering lists using filter instead of list comprehensions.
  * Mapping lists using map instead of list comprehensions.
  * Dynamically importing modules.


------------

[7] Technically, the second argument to filter can be any sequence, including
lists, tuples, and custom classes that act like lists by defining the
__getitem__ special method. If possible, filter will return the same datatype
as you give it, so filtering a list returns a list, but filtering a tuple
returns a tuple.

[8] Again, I should point out that map can take a list, a tuple, or any object
that acts like a sequence. See previous footnote about filter.

