Chapter 9. XML Processing
==========================
9.1. Diving in
---------------



These next two chapters are about XML processing in Python. It would be helpful
if you already knew what an XML document looks like, that it's made up of
structured tags to form a hierarchy of elements, and so on. If this doesn't
make sense to you, there are many XML tutorials (http://directory.google.com/
Top/Computers/Data_Formats/Markup_Languages/XML/Resources/
FAQs,_Help,_and_Tutorials/) that can explain the basics.

If you're not particularly interested in XML, you should still read these
chapters, which cover important topics like Python packages, Unicode, command
line arguments, and how to use getattr for method dispatching.

Being a philosophy major is not required, although if you have ever had the
misfortune of being subjected to the writings of Immanuel Kant, you will
appreciate the example program a lot more than if you majored in something
useful, like computer science.

There are two basic ways to work with XML. One is called SAX ("Simple API for
XML"), and it works by reading the XML a little bit at a time and calling a
method for each element it finds. (If you read Chapter 8, HTML Processing, this
should sound familiar, because that's how the sgmllib module works.) The other
is called DOM ("Document Object Model"), and it works by reading in the entire
XML document at once and creating an internal representation of it using native
Python classes linked in a tree structure. Python has standard modules for both
kinds of parsing, but this chapter will only deal with using the DOM.

The following is a complete Python program which generates pseudo-random output
based on a context-free grammar defined in an XML format. Don't worry yet if
you don't understand what that means; you'll examine both the program's input
and its output in more depth throughout these next two chapters.


Example 9.1. kgp.py
~~~~~~~~~~~~~~~~~~~~


If you have not already done so, you can download this and other examples (
http://diveintopython.org/download/diveintopython-examples-5.4.zip) used in
this book.


::

    """Kant Generator for Python
    
    Generates mock philosophy based on a context-free grammar
    
    Usage: python kgp.py [options] [source]
    
    Options:
      -g ..., --grammar=...   use specified grammar file or URL
      -h, --help              show this help
      -d                      show debugging information while parsing
    
    Examples:
      kgp.py                  generates several paragraphs of Kantian philosophy
      kgp.py -g husserl.xml   generates several paragraphs of Husserl
      kpg.py "<xref id='paragraph'/>"  generates a paragraph of Kant
      kgp.py template.xml     reads from template.xml to decide what to generate
    """
    from xml.dom import minidom
    import random
    import toolbox
    import sys
    import getopt
    
    _debug = 0
    
    class NoSourceError(Exception): pass
    
    class KantGenerator:
        """generates mock philosophy based on a context-free grammar"""
    
        def __init__(self, grammar, source=None):
            self.loadGrammar(grammar)
            self.loadSource(source and source or self.getDefaultSource())
            self.refresh()
    
        def _load(self, source):
            """load XML input source, return parsed XML document
    
            - a URL of a remote XML file ("http://diveintopython.org/kant.xml")
            - a filename of a local XML file ("~/diveintopython/common/py/kant.xml")
            - standard input ("-")
            - the actual XML document, as a string
            """
            sock = toolbox.openAnything(source)
            xmldoc = minidom.parse(sock).documentElement
            sock.close()
            return xmldoc
    
        def loadGrammar(self, grammar):                         
            """load context-free grammar"""                     
            self.grammar = self._load(grammar)                  
            self.refs = {}                                      
            for ref in self.grammar.getElementsByTagName("ref"):
                self.refs[ref.attributes["id"].value] = ref     
    
        def loadSource(self, source):
            """load source"""
            self.source = self._load(source)
    
        def getDefaultSource(self):
            """guess default source of the current grammar
            
            The default source will be one of the <ref>s that is not
            cross-referenced.  This sounds complicated but it's not.
            Example: The default source for kant.xml is
            "<xref id='section'/>", because 'section' is the one <ref>
            that is not <xref>'d anywhere in the grammar.
            In most grammars, the default source will produce the
            longest (and most interesting) output.
            """
            xrefs = {}
            for xref in self.grammar.getElementsByTagName("xref"):
                xrefs[xref.attributes["id"].value] = 1
            xrefs = xrefs.keys()
            standaloneXrefs = [e for e in self.refs.keys() if e not in xrefs]
            if not standaloneXrefs:
                raise NoSourceError, "can't guess source, and no source specified"
            return '<xref id="%s"/>' % random.choice(standaloneXrefs)
            
        def reset(self):
            """reset parser"""
            self.pieces = []
            self.capitalizeNextWord = 0
    
        def refresh(self):
            """reset output buffer, re-parse entire source file, and return output
            
            Since parsing involves a good deal of randomness, this is an
            easy way to get new output without having to reload a grammar file
            each time.
            """
            self.reset()
            self.parse(self.source)
            return self.output()
    
        def output(self):
            """output generated text"""
            return "".join(self.pieces)
    
        def randomChildElement(self, node):
            """choose a random child element of a node
            
            This is a utility method used by do_xref and do_choice.
            """
            choices = [e for e in node.childNodes
                       if e.nodeType == e.ELEMENT_NODE]
            chosen = random.choice(choices)            
            if _debug:                                 
                sys.stderr.write('%s available choices: %s\n' % \
                    (len(choices), [e.toxml() for e in choices]))
                sys.stderr.write('Chosen: %s\n' % chosen.toxml())
            return chosen                              
    
        def parse(self, node):         
            """parse a single XML node
            
            A parsed XML document (from minidom.parse) is a tree of nodes
            of various types.  Each node is represented by an instance of the
            corresponding Python class (Element for a tag, Text for
            text data, Document for the top-level document).  The following
            statement constructs the name of a class method based on the type
            of node we're parsing ("parse_Element" for an Element node,
            "parse_Text" for a Text node, etc.) and then calls the method.
            """
            parseMethod = getattr(self, "parse_%s" % node.__class__.__name__)
            parseMethod(node)
    
        def parse_Document(self, node):
            """parse the document node
            
            The document node by itself isn't interesting (to us), but
            its only child, node.documentElement, is: it's the root node
            of the grammar.
            """
            self.parse(node.documentElement)
    
        def parse_Text(self, node):    
            """parse a text node
            
            The text of a text node is usually added to the output buffer
            verbatim.  The one exception is that <p class='sentence'> sets
            a flag to capitalize the first letter of the next word.  If
            that flag is set, we capitalize the text and reset the flag.
            """
            text = node.data
            if self.capitalizeNextWord:
                self.pieces.append(text[0].upper())
                self.pieces.append(text[1:])
                self.capitalizeNextWord = 0
            else:
                self.pieces.append(text)
    
        def parse_Element(self, node): 
            """parse an element
            
            An XML element corresponds to an actual tag in the source:
            <xref id='...'>, <p chance='...'>, <choice>, etc.
            Each element type is handled in its own method.  Like we did in
            parse(), we construct a method name based on the name of the
            element ("do_xref" for an <xref> tag, etc.) and
            call the method.
            """
            handlerMethod = getattr(self, "do_%s" % node.tagName)
            handlerMethod(node)
    
        def parse_Comment(self, node):
            """parse a comment
            
            The grammar can contain XML comments, but we ignore them
            """
            pass
        
        def do_xref(self, node):
            """handle <xref id='...'> tag
            
            An <xref id='...'> tag is a cross-reference to a <ref id='...'>
            tag.  <xref id='sentence'/> evaluates to a randomly chosen child of
            <ref id='sentence'>.
            """
            id = node.attributes["id"].value
            self.parse(self.randomChildElement(self.refs[id]))
    
        def do_p(self, node):
            """handle <p> tag
            
            The <p> tag is the core of the grammar.  It can contain almost
            anything: freeform text, <choice> tags, <xref> tags, even other
            <p> tags.  If a "class='sentence'" attribute is found, a flag
            is set and the next word will be capitalized.  If a "chance='X'"
            attribute is found, there is an X% chance that the tag will be
            evaluated (and therefore a (100-X)% chance that it will be
            completely ignored)
            """
            keys = node.attributes.keys()
            if "class" in keys:
                if node.attributes["class"].value == "sentence":
                    self.capitalizeNextWord = 1
            if "chance" in keys:
                chance = int(node.attributes["chance"].value)
                doit = (chance > random.randrange(100))
            else:
                doit = 1
            if doit:
                for child in node.childNodes: self.parse(child)
    
        def do_choice(self, node):
            """handle <choice> tag
            
            A <choice> tag contains one or more <p> tags.  One <p> tag
            is chosen at random and evaluated; the rest are ignored.
            """
            self.parse(self.randomChildElement(node))
    
    def usage():
        print __doc__
    
    def main(argv):                         
        grammar = "kant.xml"                
        try:                                
            opts, args = getopt.getopt(argv, "hg:d", ["help", "grammar="])
        except getopt.GetoptError:          
            usage()                         
            sys.exit(2)                     
        for opt, arg in opts:               
            if opt in ("-h", "--help"):     
                usage()                     
                sys.exit()                  
            elif opt == '-d':               
                global _debug               
                _debug = 1                  
            elif opt in ("-g", "--grammar"):
                grammar = arg               
        
        source = "".join(args)              
    
        k = KantGenerator(grammar, source)
        print k.output()
    
    if __name__ == "__main__":
        main(sys.argv[1:])




Example 9.2. toolbox.py
~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    """Miscellaneous utility functions"""
    
    def openAnything(source):            
        """URI, filename, or string --> stream
    
        This function lets you define parsers that take any input source
        (URL, pathname to local or network file, or actual data as a string)
        and deal with it in a uniform manner.  Returned object is guaranteed
        to have all the basic stdio read methods (read, readline, readlines).
        Just .close() the object when you're done with it.
        
        Examples:
        >>> from xml.dom import minidom
        >>> sock = openAnything("http://localhost/kant.xml")
        >>> doc = minidom.parse(sock)
        >>> sock.close()
        >>> sock = openAnything("c:\\inetpub\\wwwroot\\kant.xml")
        >>> doc = minidom.parse(sock)
        >>> sock.close()
        >>> sock = openAnything("<ref id='conjunction'><text>and</text><text>or</text></ref>")
        >>> doc = minidom.parse(sock)
        >>> sock.close()
        """
        if hasattr(source, "read"):
            return source
    
        if source == '-':
            import sys
            return sys.stdin
    
        # try to open with urllib (if source is http, ftp, or file URL)
        import urllib                         
        try:                                  
            return urllib.urlopen(source)     
        except (IOError, OSError):            
            pass                              
        
        # try to open with native open function (if source is pathname)
        try:                                  
            return open(source)               
        except (IOError, OSError):            
            pass                              
        
        # treat source as string
        import StringIO                       
        return StringIO.StringIO(str(source)) 



Run the program kgp.py by itself, and it will parse the default XML-based
grammar, in kant.xml, and print several paragraphs worth of philosophy in the
style of Immanuel Kant.


Example 9.3. Sample output of kgp.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    [you@localhost kgp]$ python kgp.py
         As is shown in the writings of Hume, our a priori concepts, in
    reference to ends, abstract from all content of knowledge; in the study
    of space, the discipline of human reason, in accordance with the
    principles of philosophy, is the clue to the discovery of the
    Transcendental Deduction.  The transcendental aesthetic, in all
    theoretical sciences, occupies part of the sphere of human reason
    concerning the existence of our ideas in general; still, the
    never-ending regress in the series of empirical conditions constitutes
    the whole content for the transcendental unity of apperception.  What
    we have alone been able to show is that, even as this relates to the
    architectonic of human reason, the Ideal may not contradict itself, but
    it is still possible that it may be in contradictions with the
    employment of the pure employment of our hypothetical judgements, but
    natural causes (and I assert that this is the case) prove the validity
    of the discipline of pure reason.  As we have already seen, time (and
    it is obvious that this is true) proves the validity of time, and the
    architectonic of human reason, in the full sense of these terms,
    abstracts from all content of knowledge.  I assert, in the case of the
    discipline of practical reason, that the Antinomies are just as
    necessary as natural causes, since knowledge of the phenomena is a
    posteriori.
        The discipline of human reason, as I have elsewhere shown, is by
    its very nature contradictory, but our ideas exclude the possibility of
    the Antinomies.  We can deduce that, on the contrary, the pure
    employment of philosophy, on the contrary, is by its very nature
    contradictory, but our sense perceptions are a representation of, in
    the case of space, metaphysics.  The thing in itself is a
    representation of philosophy.  Applied logic is the clue to the
    discovery of natural causes.  However, what we have alone been able to
    show is that our ideas, in other words, should only be used as a canon
    for the Ideal, because of our necessary ignorance of the conditions.
    
    [...snip...]



This is, of course, complete gibberish. Well, not complete gibberish. It is
syntactically and grammatically correct (although very verbose -- Kant wasn't
what you would call a get-to-the-point kind of guy). Some of it may actually be
true (or at least the sort of thing that Kant would have agreed with), some of
it is blatantly false, and most of it is simply incoherent. But all of it is in
the style of Immanuel Kant.

Let me repeat that this is much, much funnier if you are now or have ever been
a philosophy major.

The interesting thing about this program is that there is nothing Kant-specific
about it. All the content in the previous example was derived from the grammar
file, kant.xml. If you tell the program to use a different grammar file (which
you can specify on the command line), the output will be completely different.


Example 9.4. Simpler output from kgp.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    [you@localhost kgp]$ python kgp.py -g binary.xml
    00101001
    [you@localhost kgp]$ python kgp.py -g binary.xml
    10110100



You will take a closer look at the structure of the grammar file later in this
chapter. For now, all you need to know is that the grammar file defines the
structure of the output, and the kgp.py program reads through the grammar and
makes random decisions about which words to plug in where.

9.2. Packages
--------------



Actually parsing an XML document is very simple: one line of code. However,
before you get to that line of code, you need to take a short detour to talk
about packages.


Example 9.5. Loading an XML document (a sneak peek)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> from xml.dom import minidom (1)
    >>> xmldoc = minidom.parse('~/diveintopython/common/py/kgp/binary.xml')

(1) This is a syntax you haven't seen before. It looks almost like the from
    module import you know and love, but the "." gives it away as something
    above and beyond a simple import. In fact, xml is what is known as a
    package, dom is a nested package within xml, and minidom is a module within
    xml.dom.


That sounds complicated, but it's really not. Looking at the actual
implementation may help. Packages are little more than directories of modules;
nested packages are subdirectories. The modules within a package (or a nested
package) are still just .py files, like always, except that they're in a
subdirectory instead of the main lib/ directory of your Python installation.


Example 9.6. File layout of a package
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    Python21/           root Python installation (home of the executable)
    |
    +--lib/             library directory (home of the standard library modules)
       |
       +-- xml/         xml package (really just a directory with other stuff in it)
           |
           +--sax/      xml.sax package (again, just a directory)
           |
           +--dom/      xml.dom package (contains minidom.py)
           |
           +--parsers/  xml.parsers package (used internally)



So when you say from xml.dom import minidom, Python figures out that that means
"look in the xml directory for a dom directory, and look in that for the
minidom module, and import it as minidom". But Python is even smarter than
that; not only can you import entire modules contained within a package, you
can selectively import specific classes or functions from a module contained
within a package. You can also import the package itself as a module. The
syntax is all the same; Python figures out what you mean based on the file
layout of the package, and automatically does the right thing.


Example 9.7. Packages are modules, too
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> from xml.dom import minidom         (1)
    >>> minidom
    <module 'xml.dom.minidom' from 'C:\Python21\lib\xml\dom\minidom.pyc'>
    >>> minidom.Element
    <class xml.dom.minidom.Element at 01095744>
    >>> from xml.dom.minidom import Element (2)
    >>> Element
    <class xml.dom.minidom.Element at 01095744>
    >>> minidom.Element
    <class xml.dom.minidom.Element at 01095744>
    >>> from xml import dom                 (3)
    >>> dom
    <module 'xml.dom' from 'C:\Python21\lib\xml\dom\__init__.pyc'>
    >>> import xml                          (4)
    >>> xml
    <module 'xml' from 'C:\Python21\lib\xml\__init__.pyc'>

(1) Here you're importing a module (minidom) from a nested package (xml.dom).
    The result is that minidom is imported into your namespace, and in order to
    reference classes within the minidom module (like Element), you need to
    preface them with the module name.
(2) Here you are importing a class (Element) from a module (minidom) from a
    nested package (xml.dom). The result is that Element is imported directly
    into your namespace. Note that this does not interfere with the previous
    import; the Element class can now be referenced in two ways (but it's all
    still the same class).
(3) Here you are importing the dom package (a nested package of xml) as a
    module in and of itself. Any level of a package can be treated as a module,
    as you'll see in a moment. It can even have its own attributes and methods,
    just the modules you've seen before.
(4) Here you are importing the root level xml package as a module.


So how can a package (which is just a directory on disk) be imported and
treated as a module (which is always a file on disk)? The answer is the magical
__init__.py file. You see, packages are not simply directories; they are
directories with a specific file, __init__.py, inside. This file defines the
attributes and methods of the package. For instance, xml.dom contains a Node
class, which is defined in xml/dom/__init__.py. When you import a package as a
module (like dom from xml), you're really importing its __init__.py file.
   
    Note: What makes a package
    A package is a directory with the special __init__.py file in it. The
    __init__.py file defines the attributes and methods of the package. It
    doesn't need to define anything; it can just be an empty file, but it has
    to exist. But if __init__.py doesn't exist, the directory is just a
    directory, not a package, and it can't be imported or contain modules or
    nested packages.


So why bother with packages? Well, they provide a way to logically group
related modules. Instead of having an xml package with sax and dom packages
inside, the authors could have chosen to put all the sax functionality in
xmlsax.py and all the dom functionality in xmldom.py, or even put all of it in
a single module. But that would have been unwieldy (as of this writing, the XML
package has over 3000 lines of code) and difficult to manage (separate source
files mean multiple people can work on different areas simultaneously).

If you ever find yourself writing a large subsystem in Python (or, more likely,
when you realize that your small subsystem has grown into a large one), invest
some time designing a good package architecture. It's one of the many things
Python is good at, so take advantage of it.

9.3. Parsing XML
-----------------



As I was saying, actually parsing an XML document is very simple: one line of
code. Where you go from there is up to you.


Example 9.8. Loading an XML document (for real this time)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> from xml.dom import minidom                                          (1)
    >>> xmldoc = minidom.parse('~/diveintopython/common/py/kgp/binary.xml')  (2)
    >>> xmldoc                                                               (3)
    <xml.dom.minidom.Document instance at 010BE87C>
    >>> print xmldoc.toxml()                                                 (4)
    <?xml version="1.0" ?>
    <grammar>
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    <ref id="byte">
      <p><xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/>\
    <xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/></p>
    </ref>
    </grammar>

(1) As you saw in the previous section, this imports the minidom module from
    the xml.dom package.
(2) Here is the one line of code that does all the work: minidom.parse takes
    one argument and returns a parsed representation of the XML document. The
    argument can be many things; in this case, it's simply a filename of an XML
    document on my local disk. (To follow along, you'll need to change the path
    to point to your downloaded examples directory.) But you can also pass a
    file object, or even a file-like object. You'll take advantage of this
    flexibility later in this chapter.
(3) The object returned from minidom.parse is a Document object, a descendant
    of the Node class. This Document object is the root level of a complex
    tree-like structure of interlocking Python objects that completely
    represent the XML document you passed to minidom.parse.
(4) toxml is a method of the Node class (and is therefore available on the
    Document object you got from minidom.parse). toxml prints out the XML that
    this Node represents. For the Document node, this prints out the entire XML
    document.


Now that you have an XML document in memory, you can start traversing through
it.


Example 9.9. Getting child nodes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> xmldoc.childNodes    (1)
    [<DOM Element: grammar at 17538908>]
    >>> xmldoc.childNodes[0] (2)
    <DOM Element: grammar at 17538908>
    >>> xmldoc.firstChild    (3)
    <DOM Element: grammar at 17538908>

(1) Every Node has a childNodes attribute, which is a list of the Node objects.
    A Document always has only one child node, the root element of the XML
    document (in this case, the grammar element).
(2) To get the first (and in this case, the only) child node, just use regular
    list syntax. Remember, there is nothing special going on here; this is just
    a regular Python list of regular Python objects.
(3) Since getting the first child node of a node is a useful and common
    activity, the Node class has a firstChild attribute, which is synonymous
    with childNodes[0]. (There is also a lastChild attribute, which is
    synonymous with childNodes[-1].)



Example 9.10. toxml works on any node
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> grammarNode = xmldoc.firstChild
    >>> print grammarNode.toxml() (1)
    <grammar>
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    <ref id="byte">
      <p><xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/>\
    <xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/></p>
    </ref>
    </grammar>

(1) Since the toxml method is defined in the Node class, it is available on any
    XML node, not just the Document element.



Example 9.11. Child nodes can be text
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> grammarNode.childNodes                  (1)
    [<DOM Text node "\n">, <DOM Element: ref at 17533332>, \
    <DOM Text node "\n">, <DOM Element: ref at 17549660>, <DOM Text node "\n">]
    >>> print grammarNode.firstChild.toxml()    (2)





::

    >>> print grammarNode.childNodes[1].toxml() (3)
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    >>> print grammarNode.childNodes[3].toxml() (4)
    <ref id="byte">
      <p><xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/>\
    <xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/></p>
    </ref>
    >>> print grammarNode.lastChild.toxml()     (5)


(1) Looking at the XML in binary.xml, you might think that the grammar has only
    two child nodes, the two ref elements. But you're missing something: the
    carriage returns! After the '<grammar>' and before the first '<ref>' is a
    carriage return, and this text counts as a child node of the grammar
    element. Similarly, there is a carriage return after each '</ref>'; these
    also count as child nodes. So grammar.childNodes is actually a list of 5
    objects: 3 Text objects and 2 Element objects.
(2) The first child is a Text object representing the carriage return after the
    '<grammar>' tag and before the first '<ref>' tag.
(3) The second child is an Element object representing the first ref element.
(4) The fourth child is an Element object representing the second ref element.
(5) The last child is a Text object representing the carriage return after the
    '</ref>' end tag and before the '</grammar>' end tag.



Example 9.12. Drilling down all the way to text
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> grammarNode
    <DOM Element: grammar at 19167148>
    >>> refNode = grammarNode.childNodes[1] (1)
    >>> refNode
    <DOM Element: ref at 17987740>
    >>> refNode.childNodes                  (2)
    [<DOM Text node "\n">, <DOM Text node "  ">, <DOM Element: p at 19315844>, \
    <DOM Text node "\n">, <DOM Text node "  ">, \
    <DOM Element: p at 19462036>, <DOM Text node "\n">]
    >>> pNode = refNode.childNodes[2]
    >>> pNode
    <DOM Element: p at 19315844>
    >>> print pNode.toxml()                 (3)
    <p>0</p>
    >>> pNode.firstChild                    (4)
    <DOM Text node "0">
    >>> pNode.firstChild.data               (5)
    u'0'

(1) As you saw in the previous example, the first ref element is
    grammarNode.childNodes[1], since childNodes[0] is a Text node for the
    carriage return.
(2) The ref element has its own set of child nodes, one for the carriage
    return, a separate one for the spaces, one for the p element, and so forth.
(3) You can even use the toxml method here, deeply nested within the document.
(4) The p element has only one child node (you can't tell that from this
    example, but look at pNode.childNodes if you don't believe me), and it is a
    Text node for the single character '0'.
(5) The .data attribute of a Text node gives you the actual string that the
    text node represents. But what is that 'u' in front of the string? The
    answer to that deserves its own section.

9.4. Unicode
-------------



Unicode is a system to represent characters from all the world's different
languages. When Python parses an XML document, all data is stored in memory as
unicode.

You'll get to all that in a minute, but first, some background.

Historical note. Before unicode, there were separate character encoding systems
for each language, each using the same numbers (0-255) to represent that
language's characters. Some languages (like Russian) have multiple conflicting
standards about how to represent the same characters; other languages (like
Japanese) have so many characters that they require multiple-byte character
sets. Exchanging documents between systems was difficult because there was no
way for a computer to tell for certain which character encoding scheme the
document author had used; the computer only saw numbers, and the numbers could
mean different things. Then think about trying to store these documents in the
same place (like in the same database table); you would need to store the
character encoding alongside each piece of text, and make sure to pass it
around whenever you passed the text around. Then think about multilingual
documents, with characters from multiple languages in the same document. (They
typically used escape codes to switch modes; poof, you're in Russian koi8-r
mode, so character 241 means this; poof, now you're in Mac Greek mode, so
character 241 means something else. And so on.) These are the problems which
unicode was designed to solve.

To solve these problems, unicode represents each character as a 2-byte number,
from 0 to 65535.[5] Each 2-byte number represents a unique character used in at
least one of the world's languages. (Characters that are used in multiple
languages have the same numeric code.) There is exactly 1 number per character,
and exactly 1 character per number. Unicode data is never ambiguous.

Of course, there is still the matter of all these legacy encoding systems.
7-bit ASCII, for instance, which stores English characters as numbers ranging
from 0 to 127. (65 is capital "A", 97 is lowercase "a", and so forth.) English
has a very simple alphabet, so it can be completely expressed in 7-bit ASCII.
Western European languages like French, Spanish, and German all use an encoding
system called ISO-8859-1 (also called "latin-1"), which uses the 7-bit ASCII
characters for the numbers 0 through 127, but then extends into the 128-255
range for characters like n-with-a-tilde-over-it (241), and
u-with-two-dots-over-it (252). And unicode uses the same characters as 7-bit
ASCII for 0 through 127, and the same characters as ISO-8859-1 for 128 through
255, and then extends from there into characters for other languages with the
remaining numbers, 256 through 65535.

When dealing with unicode data, you may at some point need to convert the data
back into one of these other legacy encoding systems. For instance, to
integrate with some other computer system which expects its data in a specific
1-byte encoding scheme, or to print it to a non-unicode-aware terminal or
printer. Or to store it in an XML document which explicitly specifies the
encoding scheme.

And on that note, let's get back to Python.

Python has had unicode support throughout the language since version 2.0. The
XML package uses unicode to store all parsed XML data, but you can use unicode
anywhere.


Example 9.13. Introducing unicode
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> s = u'Dive in'            (1)
    >>> s
    u'Dive in'
    >>> print s                   (2)
    Dive in

(1) To create a unicode string instead of a regular ASCII string, add the
    letter "u" before the string. Note that this particular string doesn't have
    any non-ASCII characters. That's fine; unicode is a superset of ASCII (a
    very large superset at that), so any regular ASCII string can also be
    stored as unicode.
(2) When printing a string, Python will attempt to convert it to your default
    encoding, which is usually ASCII. (More on this in a minute.) Since this
    unicode string is made up of characters that are also ASCII characters,
    printing it has the same result as printing a normal ASCII string; the
    conversion is seamless, and if you didn't know that s was a unicode string,
    you'd never notice the difference.



Example 9.14. Storing non-ASCII characters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> s = u'La Pe\xf1a'         (1)
    >>> print s                   (2)
    Traceback (innermost last):
      File "<interactive input>", line 1, in ?
    UnicodeError: ASCII encoding error: ordinal not in range(128)
    >>> print s.encode('latin-1') (3)
    La Pe a

(1) The real advantage of unicode, of course, is its ability to store non-ASCII
    characters, like the Spanish " " (n with a tilde over it). The unicode
    character code for the tilde-n is 0xf1 in hexadecimal (241 in decimal),
    which you can type like this: \xf1.
(2) Remember I said that the print function attempts to convert a unicode
    string to ASCII so it can print it? Well, that's not going to work here,
    because your unicode string contains non-ASCII characters, so Python raises
    a UnicodeError error.
(3) Here's where the conversion-from-unicode-to-other-encoding-schemes comes
    in. s is a unicode string, but print can only print a regular string. To
    solve this problem, you call the encode method, available on every unicode
    string, to convert the unicode string to a regular string in the given
    encoding scheme, which you pass as a parameter. In this case, you're using
    latin-1 (also known as iso-8859-1), which includes the tilde-n (whereas the
    default ASCII encoding scheme did not, since it only includes characters
    numbered 0 through 127).


Remember I said Python usually converted unicode to ASCII whenever it needed to
make a regular string out of a unicode string? Well, this default encoding
scheme is an option which you can customize.


Example 9.15. sitecustomize.py
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    # sitecustomize.py                   (1)
    # this file can be anywhere in your Python path,
    # but it usually goes in ${pythondir}/lib/site-packages/
    import sys
    sys.setdefaultencoding('iso-8859-1') (2)



(1) sitecustomize.py is a special script; Python will try to import it on
    startup, so any code in it will be run automatically. As the comment
    mentions, it can go anywhere (as long as import can find it), but it
    usually goes in the site-packages directory within your Python lib
    directory.
(2) setdefaultencoding function sets, well, the default encoding. This is the
    encoding scheme that Python will try to use whenever it needs to
    auto-coerce a unicode string into a regular string.



Example 9.16. Effects of setting the default encoding
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> import sys
    >>> sys.getdefaultencoding() (1)
    'iso-8859-1'
    >>> s = u'La Pe\xf1a'
    >>> print s                  (2)
    La Pe a

(1) This example assumes that you have made the changes listed in the previous
    example to your sitecustomize.py file, and restarted Python. If your
    default encoding still says 'ascii', you didn't set up your
    sitecustomize.py properly, or you didn't restart Python. The default
    encoding can only be changed during Python startup; you can't change it
    later. (Due to some wacky programming tricks that I won't get into right
    now, you can't even call sys.setdefaultencoding after Python has started
    up. Dig into site.py and search for "setdefaultencoding" to find out how.)
(2) Now that the default encoding scheme includes all the characters you use in
    your string, Python has no problem auto-coercing the string and printing
    it.



Example 9.17. Specifying encoding in .py files
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


If you are going to be storing non-ASCII strings within your Python code,
you'll need to specify the encoding of each individual .py file by putting an
encoding declaration at the top of each file. This declaration defines the .py
file to be UTF-8:


::

    #!/usr/bin/env python
    # -*- coding: UTF-8 -*-



Now, what about XML? Well, every XML document is in a specific encoding. Again,
ISO-8859-1 is a popular encoding for data in Western European languages. KOI8-R
is popular for Russian texts. The encoding, if specified, is in the header of
the XML document.


Example 9.18. russiansample.xml
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~




::

    <?xml version="1.0" encoding="koi8-r"?>       (1)
    <preface>
    <title>??????????????????????</title>                    (2)
    </preface>



(1) This is a sample extract from a real Russian XML document; it's part of a
    Russian translation of this very book. Note the encoding, koi8-r, specified
    in the header.
(2) These are Cyrillic characters which, as far as I know, spell the Russian
    word for "Preface". If you open this file in a regular text editor, the
    characters will most likely like gibberish, because they're encoded using
    the koi8-r encoding scheme, but they're being displayed in iso-8859-1.



Example 9.19. Parsing russiansample.xml
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> from xml.dom import minidom
    >>> xmldoc = minidom.parse('russiansample.xml') (1)
    >>> title = xmldoc.getElementsByTagName('title')[0].firstChild.data
    >>> title                                       (2)
    u'\u041f\u0440\u0435\u0434\u0438\u0441\u043b\u043e\u0432\u0438\u0435'
    >>> print title                                 (3)
    Traceback (innermost last):
      File "<interactive input>", line 1, in ?
    UnicodeError: ASCII encoding error: ordinal not in range(128)
    >>> convertedtitle = title.encode('koi8-r')     (4)
    >>> convertedtitle
    '\xf0\xd2\xc5\xc4\xc9\xd3\xcc\xcf\xd7\xc9\xc5'
    >>> print convertedtitle                        (5)
    ??????????????????????

(1) I'm assuming here that you saved the previous example as russiansample.xml
    in the current directory. I am also, for the sake of completeness, assuming
    that you've changed your default encoding back to 'ascii' by removing your
    sitecustomize.py file, or at least commenting out the setdefaultencoding
    line.
(2) Note that the text data of the title tag (now in the title variable, thanks
    to that long concatenation of Python functions which I hastily skipped over
    and, annoyingly, won't explain until the next section) -- the text data
    inside the XML document's title element is stored in unicode.
(3) Printing the title is not possible, because this unicode string contains
    non-ASCII characters, so Python can't convert it to ASCII because that
    doesn't make sense.
(4) You can, however, explicitly convert it to koi8-r, in which case you get a
    (regular, not unicode) string of single-byte characters (f0, d2, c5, and so
    forth) that are the koi8-r-encoded versions of the characters in the
    original unicode string.
(5) Printing the koi8-r-encoded string will probably show gibberish on your
    screen, because your Python IDE is interpreting those characters as
    iso-8859-1, not koi8-r. But at least they do print. (And, if you look
    carefully, it's the same gibberish that you saw when you opened the
    original XML document in a non-unicode-aware text editor. Python converted
    it from koi8-r into unicode when it parsed the XML document, and you've
    just converted it back.)


To sum up, unicode itself is a bit intimidating if you've never seen it before,
but unicode data is really very easy to handle in Python. If your XML documents
are all 7-bit ASCII (like the examples in this chapter), you will literally
never think about unicode. Python will convert the ASCII data in the XML
documents into unicode while parsing, and auto-coerce it back to ASCII whenever
necessary, and you'll never even notice. But if you need to deal with that in
other languages, Python is ready.

Further reading
   
  * Unicode.org (http://www.unicode.org/) is the home page of the unicode
    standard, including a brief technical introduction (http://www.unicode.org/
    standard/principles.html).
  * Unicode Tutorial (http://www.reportlab.com/i18n/
    python_unicode_tutorial.html) has some more examples of how to use Python's
    unicode functions, including how to force Python to coerce unicode into
    ASCII even when it doesn't really want to.
  * PEP 263 (http://www.python.org/peps/pep-0263.html) goes into more detail
    about how and when to define a character encoding in your .py files.

9.5. Searching for elements
----------------------------



Traversing XML documents by stepping through each node can be tedious. If
you're looking for something in particular, buried deep within your XML
document, there is a shortcut you can use to find it quickly:
getElementsByTagName.

For this section, you'll be using the binary.xml grammar file, which looks like
this:


Example 9.20. binary.xml
~~~~~~~~~~~~~~~~~~~~~~~~~



.. sourcecode:: python

    <?xml version="1.0"?>
    <!DOCTYPE grammar PUBLIC "-//diveintopython.org//DTD Kant Generator Pro v1.0//EN" "kgp.dtd">
    <grammar>
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    <ref id="byte">
      <p><xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/>\
    <xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/></p>
    </ref>
    </grammar>



It has two refs, 'bit' and 'byte'. A bit is either a '0' or '1', and a byte is
8 bits.


Example 9.21. Introducing getElementsByTagName
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> from xml.dom import minidom
    >>> xmldoc = minidom.parse('binary.xml')
    >>> reflist = xmldoc.getElementsByTagName('ref') (1)
    >>> reflist
    [<DOM Element: ref at 136138108>, <DOM Element: ref at 136144292>]
    >>> print reflist[0].toxml()
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    >>> print reflist[1].toxml()
    <ref id="byte">
      <p><xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/>\
    <xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/></p>
    </ref>

(1) getElementsByTagName takes one argument, the name of the element you wish
    to find. It returns a list of Element objects, corresponding to the XML
    elements that have that name. In this case, you find two ref elements.



Example 9.22. Every element is searchable
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> firstref = reflist[0]                      (1)
    >>> print firstref.toxml()
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    >>> plist = firstref.getElementsByTagName("p") (2)
    >>> plist
    [<DOM Element: p at 136140116>, <DOM Element: p at 136142172>]
    >>> print plist[0].toxml()                     (3)
    <p>0</p>
    >>> print plist[1].toxml()
    <p>1</p>

(1) Continuing from the previous example, the first object in your reflist is
    the 'bit' ref element.
(2) You can use the same getElementsByTagName method on this Element to find
    all the <p> elements within the 'bit' ref element.
(3) Just as before, the getElementsByTagName method returns a list of all the
    elements it found. In this case, you have two, one for each bit.



Example 9.23. Searching is actually recursive
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> plist = xmldoc.getElementsByTagName("p") (1)
    >>> plist
    [<DOM Element: p at 136140116>, <DOM Element: p at 136142172>, <DOM Element: p at 136146124>]
    >>> plist[0].toxml()                         (2)
    '<p>0</p>'
    >>> plist[1].toxml()
    '<p>1</p>'
    >>> plist[2].toxml()                         (3)
    '<p><xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/>\
    <xref id="bit"/><xref id="bit"/><xref id="bit"/><xref id="bit"/></p>'

(1) Note carefully the difference between this and the previous example.
    Previously, you were searching for p elements within firstref, but here you
    are searching for p elements within xmldoc, the root-level object that
    represents the entire XML document. This does find the p elements nested
    within the ref elements within the root grammar element.
(2) The first two p elements are within the first ref (the 'bit' ref).
(3) The last p element is the one within the second ref (the 'byte' ref).

9.6. Accessing element attributes
----------------------------------



XML elements can have one or more attributes, and it is incredibly simple to
access them once you have parsed an XML document.

For this section, you'll be using the binary.xml grammar file that you saw in
the previous section.
   
    Note: XML attributes and Python attributes
    This section may be a little confusing, because of some overlapping
    terminology. Elements in an XML document have attributes, and Python
    objects also have attributes. When you parse an XML document, you get a
    bunch of Python objects that represent all the pieces of the XML document,
    and some of these Python objects represent attributes of the XML elements.
    But the (Python) objects that represent the (XML) attributes also have (
    Python) attributes, which are used to access various parts of the (XML)
    attribute that the object represents. I told you it was confusing. I am
    open to suggestions on how to distinguish these more clearly.



Example 9.24. Accessing element attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> xmldoc = minidom.parse('binary.xml')
    >>> reflist = xmldoc.getElementsByTagName('ref')
    >>> bitref = reflist[0]
    >>> print bitref.toxml()
    <ref id="bit">
      <p>0</p>
      <p>1</p>
    </ref>
    >>> bitref.attributes          (1)
    <xml.dom.minidom.NamedNodeMap instance at 0x81e0c9c>
    >>> bitref.attributes.keys()   (2) (3)
    [u'id']
    >>> bitref.attributes.values() (4)
    [<xml.dom.minidom.Attr instance at 0x81d5044>]
    >>> bitref.attributes["id"]    (5)
    <xml.dom.minidom.Attr instance at 0x81d5044>

(1) Each Element object has an attribute called attributes, which is a
    NamedNodeMap object. This sounds scary, but it's not, because a
    NamedNodeMap is an object that acts like a dictionary, so you already know
    how to use it.
(2) Treating the NamedNodeMap as a dictionary, you can get a list of the names
    of the attributes of this element by using attributes.keys(). This element
    has only one attribute, 'id'.
(3) Attribute names, like all other text in an XML document, are stored in
    unicode.
(4) Again treating the NamedNodeMap as a dictionary, you can get a list of the
    values of the attributes by using attributes.values(). The values are
    themselves objects, of type Attr. You'll see how to get useful information
    out of this object in the next example.
(5) Still treating the NamedNodeMap as a dictionary, you can access an
    individual attribute by name, using normal dictionary syntax. (Readers who
    have been paying extra-close attention will already know how the
    NamedNodeMap class accomplishes this neat trick: by defining a __getitem__
    special method. Other readers can take comfort in the fact that they don't
    need to understand how it works in order to use it effectively.)



Example 9.25. Accessing individual attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



::

    >>> a = bitref.attributes["id"]
    >>> a
    <xml.dom.minidom.Attr instance at 0x81d5044>
    >>> a.name  (1)
    u'id'
    >>> a.value (2)
    u'bit'

(1) The Attr object completely represents a single XML attribute of a single
    XML element. The name of the attribute (the same name as you used to find
    this object in the bitref.attributes NamedNodeMap pseudo-dictionary) is
    stored in a.name.
(2) The actual text value of this XML attribute is stored in a.value.

    Note: Attributes have no order
    Like a dictionary, attributes of an XML element have no ordering.
    Attributes may happen to be listed in a certain order in the original XML
    document, and the Attr objects may happen to be listed in a certain order
    when the XML document is parsed into Python objects, but these orders are
    arbitrary and should carry no special meaning. You should always access
    individual attributes by name, like the keys of a dictionary.

9.7. Segue
-----------



OK, that's it for the hard-core XML stuff. The next chapter will continue to
use these same example programs, but focus on other aspects that make the
program more flexible: using streams for input processing, using getattr for
method dispatching, and using command-line flags to allow users to reconfigure
the program without changing the code.

Before moving on to the next chapter, you should be comfortable doing all of
these things:
   
  * Parsing XML documents using minidom, searching through the parsed
    document, and accessing arbitrary element attributes and element children
  * Organizing complex libraries into packages
  * Converting unicode strings to different character encodings


------------

[5] This, sadly, is still an oversimplification. Unicode now has been extended
to handle ancient Chinese, Korean, and Japanese texts, which had so many
different characters that the 2-byte unicode system could not represent them
all. But Python doesn't currently support that out of the box, and I don't know
if there is a project afoot to add it. You've reached the limits of my
expertise, sorry.

